[
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/ai/",
	"title": "AI",
	"tags": [],
	"description": "",
	"content": " Amazon Connect + Lex 构建智能聊天机器人 Deep Learning AMI下 Tensorflow环境的安装与切换 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/bi/",
	"title": "BI",
	"tags": [],
	"description": "",
	"content": " 从Aurora迁移到Redshift并利用Quicksight做数据可视化分析 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/bi/aurora_redshift_quicksight/",
	"title": "从Aurora迁移到Redshift并利用Quicksight做数据可视化分析",
	"tags": [],
	"description": "",
	"content": " 实验介绍 利用terraform模板启动DMS任务\n架构图 实验前提  确保您的本机已经安装 Terraform （https://www.terraform.io/） 提前创建好EC2的秘钥对 事先用AWSCLI，aws configure配置好了凭证以有权启动这些资源  步骤 步骤1： 替换terraform变量 替换variable.tf里面的参数, 包括：VPC，DB subnet,EC2 subnet，EC2 key pair, region \u0026amp; 相应地区的AMI ID。\n补充说明: 默认在us-west-2，因启动脚本用了yum install \u0026amp; wget等命令, 如果要换区域，请尽量添加Amazon Linux AMI确保这些命令可以正常运行\n步骤2： 启动terrform模板\nterraform init terraform apply  成功后会创建好以下相关资源 ,且bastion EC2已通过启动脚本(mysql_init.tpl)加载好了Aurora的实验数据。\n记下这些output\nOutputs Example: Aurora database name = lab Aurora endpoint = tf-xxxxxxx.us-west-2.rds.amazonaws.com Aurora master password = xxxx Aurora master username = root DMS Aurora Source ID = pdaxxx DMS RedShift Target ID = ehjxxxx DMS instanace name = vipxxxx EC2 Bastion Endpoint = RedShift Endpoint = xxxxxx.us-west-2.redshift.amazonaws.com RedShift database name = lab RedShift master password = 3GMxxxx Redshift master username = root Quicksight security group = sg-xxxx  步骤3： 创建DMS任务\n新建一个DMS任务，指定好source \u0026amp; target \u0026amp; replication instance \u0026amp; mapping table （schema name: lab）\n当status为Load complete时，DMS任务执行完毕，检查table loaded这一栏应为1，full load rows为41188.\n步骤4： Quicksight数据可视化\n右上角切换Quicksight区域到指定区域如Oregon, 测试从Aurora或者redshift加载数据。\n因为Aurora和redshift均在私有子网当中，因此首先需要给Quicksight加一个VPC connection。\n 添加VPC connection\n右上角选择用户名\u0026mdash;下拉tab:manage quicksight \u0026mdash; 左侧tab:manage VPC connections \u0026ndash;add VPC connection\n选择VPC ID和output当中的Quicksight security group，以创建VPC连接\n注:\n（1）如没有mange VPC connections的选项，需要先开启enterprise版本\n（2）这里Quicksight的端口为全开，因此aurora和redshift均可以使用这一安全组做连接。实际生产请开启自己需要的端口。\n 数据可视化\n选择Aurora或redshift实例为数据源，选择刚才创建的vpc connection. database name:lab。输入用户名密码（在output当中）\nvalidate确保connectivity没问题后，即可创建。\n左侧可以看到age, job, marital这几栏。任意拖拽数据栏生成自己的dashboard\n  步骤5: 销毁资源\nterraform destroy  Note: 由于一些依赖关系，destroy命令可能会报错，这时手动删除报错资源再运行此命令销毁其他资源即可。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/mobile/",
	"title": "Mobile",
	"tags": [],
	"description": "",
	"content": " Cognito实现微信用户第三方登陆 S3图片处理 Cognito, OpenID Connect实现S3精细化权限控制 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/mobile/serverless-image-handler/",
	"title": "S3图片处理",
	"tags": [],
	"description": "",
	"content": " 如果您使用的是AWS Global Region, 您可以停止阅读本文，转向使用Serverless Image Hanlder提供的CloudFormation时间自动部署。\n本文提到的部署方式，仅适用于AWS China; 关于能够实现那些图片处理功能，请参考文档\n修改源代码，配置参数 点击此处下载源代码\n 修改image_handler/thumbor.conf\n TC_AWS_REGION 定义为 cn-northwest-1 或者 cn-north-1 TC_AWS_ENDPOINT 定义为https://s3.cn-northwest-1.amazonaws.com.cn 和https://s3.cn-north-1.amazonaws.com.cn TC_AWS_LOADER_BUCKET 定义为源S3的bucket名称  修改tc_aws/__init__.py\n TC_AWS_REGION 定义为 cn-northwest-1或者cn-north-1 TC_AWS_LOADER_BUCKET 定义为源S3的bucket名称 TC_AWS_ENDPOINT 定义为https://s3.cn-northwest-1.amazonaws.com.cn 或者 https://s3.cn-north-1.amazonaws.com.cn    本文的源代码与global region的源代码还存在以下几处修改，在本文的源代码中已经更改，用户无需再次修改\n  修改image_handler/thumbor.conf\n ALLOW_UNSAFE_URL 定义为 True（提供的代码已经更改）  修改thumbor/thumbor.conf\n ALLOW_UNSAFE_URL 改成 True（提供的代码已经更改）  修改image_handler/lambda_function.py\nif str(os.environ.get('ENABLE_CORS')).upper() == \u0026quot;YES\u0026quot;: api_response['headers']['Access-Control-Allow-Origin'] = os.environ.get('CORS_ORIGIN')   改成\napi_response['headers']['Access-Control-Allow-Origin'] = os.environ.get('*')  上传代码至S3  打包源文件（工程文件必须位于压缩包一级目录） 上传到与 Lambda, API Gateway 在同一个region的S3  配置 IAM Role 创建一个供Lambda使用的 IAM Role, 并且包括如下两条policy\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;logs:CreateLogGroup\u0026quot;, \u0026quot;logs:CreateLogStream\u0026quot;, \u0026quot;logs:PutLogEvents\u0026quot; ], \u0026quot;Resource\u0026quot;: \u0026quot;arn:aws-cn:logs:*:*:*\u0026quot; } ] }  以上policy允许Lambda将日志写到CloudWatch Logs\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Action\u0026quot;: [ \u0026quot;s3:GetObject\u0026quot;, \u0026quot;s3:ListBucket\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws-cn:s3:::\u0026lt;bucket-name\u0026gt;/*\u0026quot;, \u0026quot;arn:aws-cn:s3:::\u0026lt;bucket-name\u0026gt;\u0026quot; ], \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot; } ] }  将\u0026lt;bucket-name\u0026gt;替换成源S3 bucket 名称。\n创建Lambda  创建Lambda函数，选择 Python 2.7 执行环境 选择刚才创建的IAM Role 在 Function Code 部分，选择upload a file from Amazon S3 在 Amazon S3 link URL，输入压缩包的S3的URL链接 在 Handler，输入image_handler/lambda_function.lambda_handler 在 Basic settings, 将 Memory 调整到 1536MB 或以上 在 Basic settings，将 Timeout 调整到 10 sec 点击保存  创建API Gateway  在API Gateway页面，点击 Create API, 输入 API name 在Resouces页面，点击Actions, 选择 Create Resource 勾选Configure as proxy resource 勾选Enable API Gateway CORS，并选择 Create Resource 选择 Lambda Function Proxy 选择正确的Lambda region 输入Lambda Function的名称，并选择Save 在弹出的确认窗口选择OK 在左侧导航栏，选择 Settings 选择Add Binary Media Type，并输入*/* 选择Save Changes 在左侧导航栏，选择Resources，点击Actions并选择Deploy API 在Deployment stage 选择New Stage，并输入名称，选择Deploy 拷贝Invoke URL [可选]在左侧导航栏选择Stages, 并点击刚才创建的Stage [可选]在Cache Settings选择Enable API cache，选择Cache Capacity [可选]在Cache time-to-live (TTL)输入TTL,并保存  开启 API Gateway Cache 会减少 Lambda的执行次数，从而提供相同requet请求时的响应时间。\n测试自动切图功能  浏览器输入 https://\u0026lt;api-gateway-invoke-url\u0026gt;/fit-in/300x400/\u0026lt;s3-object-key\u0026gt;，例如https://fwgzof7dee.execute-api.cn-northwest-1.amazonaws.com.cn/dev/fit-in/300x400/demo/flower.jpg获得300x400的切图 浏览器输入 https://\u0026lt;api-gateway-invoke-url\u0026gt;/filters:blur(7)/\u0026lt;s3-object-key\u0026gt;，例如https://fwgzof7dee.execute-api.cn-northwest-1.amazonaws.com.cn/dev/filters:blur(7)/demo/flower.jpg获得模糊图片  支持的Filter，请参考Serverless Imager Handler Appendix A: Supported Filters\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/mobile/cognito_android/",
	"title": "基于Cognito的微信第三方登陸系統",
	"tags": [],
	"description": "",
	"content": " 步驟  App发起授权，应用唤起微信客戶端，诱导用戶点击授权按鈕 用戶点击授权按钮后 APP得到auth code 应用用auth code作为参数向远端的api发起请求 API 发送auth code到微信接口 返回用戶的openId和AccessToken API发送AccessToken到微信接口 返回userinfo 包括用戶昵稱 头像等信息 API向dynamo DB中加入一条用戶信息 返回得到userId API 將userId和身份池Id发送到cognito接口 返回user的IdentityId和token 将token和 identityId存入dynamo DB API將token和IdentityId userId 返回給客戶端APP 客戶端APP可以用identity 身份池Id context上下文 region和auth code喚起client, 最后用client訪問AWS資源  QA：  步驟原理如上图所示 为什么要进行二次访问： A： 为了得到用户信息，如头像，昵称等 微信的认证授权协议： A: Auth2 允许用户访问个人信息 用户拥有的权限 A：同身份池的权限 准备 A: AWS账号 创建身份池 设定用户的权限 APP在微信公开平台的ID和密钥 Cognito是什么 A：Amazon Cognito 为您的 Web 和移动应用程序提供身份验证、授权和用户管理。您的用户可使用用户名和密码直接登录，也可以通过第三方 (如 Facebook、Amazon 或 Google) 登录。 https://aws.amazon.com/cn/documentation/cognito/?id=docs_gateway 每一个part的作用 数据库用于记录保存用户信息 Cognito通过对身份池的管理对用户做授权 API gateway:微信接只能由后台访问所以用lambda实现， IOS兼容性 AWS提供兼容IOS的开发工具包  code: https://github.com/xfsnow/android/tree/master/CognitoWX\nhttps://github.com/xfsnow/serverless/tree/master/cognitowx\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/alexa/",
	"title": "Alexa",
	"tags": [],
	"description": "",
	"content": " Cognito User Pool实现账户关联 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/alexa/account-linking-cognito/",
	"title": "AWS Cognito User Pool实现Alexa账户关联",
	"tags": [],
	"description": "",
	"content": "  完成本实验预计使用1小时 完成该实验需要可以一个已经注册好的 Alexa Skill, 并且能够在 Alexa App 或者 Alex Web Portal 中显示该 Alexa Skill。\n 本文将介绍如何利用AWS Cognito User Pool实现Alexa的账户关联。这里将不涉及到 Cognito 或者 Alexa 相关的开发。有关 Cognito User Pool 的更多资料请参考 官方文档。 有关Alexa的开发资料请参考 Alexa Developer Portal。\n什么是账户关联 账户关联(Account Linking)允许将用户在Alexa账号系统中的身份与另外一个账号系统中的身份关联起来。 假设这样的一个问题，系统X中存在用户a和用户b, Alexa 账户体系中存在用户A和用户B, 那么系统X收到来自 Alexa的指令后，如何区分这是来自用户a的请求还是用户b的呢？账户关联就是为了解决这个问题，将Alexa的账户 系统与另一个账号系统中的身份关联起来。\nAlexa账户关联是标准的 OAuth2.0 授权, 本文不深入探讨 OAuth2.0, 有关 OAuth2.0 的理解可以参考 理解OAuth 2.0。\nAWS的 Cognito User Pool提 供了标准的 OAuth 2.0 的认证和授权，因此借助 Cognito User Pool 可以快速实现和 Alexa 的账户关联。\n下面这张流程图展示了一个用户在 Alexa APP 中进行账户关联，Alexa 是如何从授权服务器获得 AccessToken 的整个过程。\n在完成 Alexa 的账户关联之后，用户与 Skill 交互产生的指令会被发送到 Resource Server, 该指令中包含用户的 AccessToken。 这里的 Resource Server 就是 Alexa Kill 控制中配置的 Endpoint。\n在 Resource Server 上，通过 Decode AccessToken, 能够获得用户名。\n配置Cognito User Pool AWS Cognito User Pool提供了基于OAuth 2.0的实现，这里提供详细的Cognito User Pool的配置流程。\n创建Cognito User Pool  打开 Amazon Cognito Console。\n 选择 管理用户池。\n 在页面右上角，选择创建用户池。\n 为您的用户池指定一个名称，然后选择查看默认值以保存该名称。\n 在属性页面上，选择电子邮件地址或电话号码，然后选择允许使用电子邮件地址。\n 在页面底部，选择下一步以保存属性。\n 在页面左侧的导航栏上，选择审核。\n 在审核页面底部，选择创建池。\n  创建应用程序客户端 您可以为用户池创建多个应用程序，通常一个应用程序对应于该应用程序的平台。在和Alexa的结合的 场景中，Alexa是用户池的一个应用程序客户端。\n 在页面左侧的导航栏上，选择应用程序客户端。\n 在应用程序客户端选项卡中，选择添加应用程序客户端\n 指定应用程序客户端名称\n 指定应用程序的刷新令牌的到期时间 (天)。默认值是 30。 您可以将其更改为 1 到 3650 之间的任何值。\n 在页面底部，选择创建应用程序客户端。\n  配置应用程序客户端 OAuth 2.0 设置 默认情况下应用程序客户端的 OAuth 2.0 是不开放的，按照以下步骤，打开客户端的 OAuth 2.0 认证与授权。\n 在页面左侧的导航栏上，选择应用程序客户端设置。\n 找到刚才创建的应用程序客户端。\n 在启用身份提供商中，选择 Cognito User Pool 。\n 在回调 URL 中，指定 Alexa Kill 的 Redirect URLs。\n   在 Alexa Console 中选择需要配置的 Alexa Skill, 在左侧页面导航栏选择 Account Linking, 网页底部找到的 Redirect URLs。\nAlexa 根据用户在哪里注册的设备，跳转到不同的URL, 为了服务所有Alexa用户，建议将三个Redirect URL都填入Cognito，点击查看更多信息\n  在允许的 OAuth 流程中，选择 Authorization code grant。\n 在许的 OAuth 范围中，至少选择 openid。\n 选择保存修改。\n  配置 Cognito User Pool 认证域名 Cognito 域名是 Alexa 进行 OAuth2.0 认证时的跳转域名。默认的域名为https://\u0026lt;domain-prefix\u0026gt;.auth.\u0026lt;region\u0026gt;.amazoncognito.com。 您可以配置自己的域名，关于如何配置自己的域名，请参考将自定义域添加到用户池。 本文将使用AWS提供的默认域名。\n 在页面左侧的导航栏上，选择域名。\n 指定您的域名，选择检查可用性。\n 当提示为此域可用后，选择保存更改。\n   请记录 Cognito User Pool 的认证域名，可以使用默认域名或者自己的域名，在后续的Alexa配置中需要使用。\n 配置 Amazon Cognito认证UI（可选） Amazon Cognito提供默认的UI, 如下图:\n可以根据自定义内置登录网页和注册网页 修改登录的页面。如果不希望使用Cognito提供的登录和注册页面，也可以根据API自己实现。\n配置Alexa Account Linking 此章节将配置Alex Account Linking, 这里假设已经创建了一个*Alexa SkillSet*或者*Alexa SmartHome Skill*。\n 登录Alexa 控制台。\n 在 Skills 列表页中，选择需要做账户关联的技能。\n 在左侧页面导航栏中，选择 Account Linking。\n 打开\u0026rdquo;是否允许账号\u0026rdquo;的开关。\n 在 Security Provider Information 中，选择 Auth Code Grant。\n 在 Authorization URI 中，指定 https://\u0026lt;your-cognito-domain\u0026gt;/oauth2/authorize。\n 在 Access Token URI 中，指定 https://\u0026lt;your-cognito-domain\u0026gt;/oauth2/token。\n 在 Client ID 中，指定 Cognito 应用程序客户端的应用程序客户端 ID。\n   在Cognito控制台左侧选择应用程序客户端, 点击显示详细信息，可以查看应用程序客户端 ID和应用程序客户端密钥。\n  在Client Secret，指定Cognito应用程序客户端的应用程序客户端密钥。   在页面左上角，选择Save。\n （可选）如果是 Custom Skill, 需要重新 Build Skill。选择左侧页面导航栏中的 CUSTOM, 选择 Invocation, 点击 Build Model 按钮，等待 Build Success 的提示。\n  关于更多 Cognito OAuth2.0 的 URI, 请参考Amazon Cognito 用户池 Auth API 参考\n在Alexa App中绑定用户身份 创建测试用户  打开 Amazon Cognito Console。\n 选择刚才创建的用户池。\n 在页面左侧导航栏中，选择用户和组。\n 选择创建用户，并指定用户名, 临时密码, 电话号码及电子邮件，并选择创建用户。\n  账户关联  Alexa APP的登录账号，必须和登录Alexa Developer控制台的账号相同，才能看见开发中的Alexa技能。\n  在手机上打开 Alexa APP, 或者使用 Alexa Web Portal。\n 在 APP 左上角，选择\u0026rdquo;汉堡\u0026rdquo;按钮。\n 在左侧导航栏页面中，选择 Skills。\n 在 All Skills 页面右上角，选择 Your Skills。\n 在 Your Skills 页面，选择 DEV SKILLS, 此处将列出所有开发中的技能。\n 选择创建的 Alexa 技能，在详情页，选择 Enable。如果已经显示为 Enable，可以先选择 Disable 之后，再次 Enable。\n 在弹出的登录页面中，输入 Cognito User Pool 中用户账号和密码。\n (可选) Cognito User Pool 在第一次登录之后，需要修改初始密码。\n 账户关联成功。\n  此时，账号已经关联成功，Alexa 在后续发送给 HTTP Endpoint 或者 AWS Lambda 的消息体中均会包含用户的 accessToken, 该 accessToken 为 JWT 格式。Alexa 发送的 JWT token 中的 sub 字段就是 Cognito User Pool 中的用户名。\n更多阅读 Understand Account Linking\nThe OAuth2.0 Authorization Framework\nJSON Web Token\nAWS Cognito User Pool\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/iot/",
	"title": "IOT",
	"tags": [],
	"description": "",
	"content": " IoT系列动手实验 \u0026ensp;\u0026ensp;\u0026ensp; IoT Core 实验1\n\u0026ensp;\u0026ensp;\u0026ensp; IoT Core 实验2\n\u0026ensp;\u0026ensp;\u0026ensp; IoT Greengrass实验\n\u0026ensp;\u0026ensp;\u0026ensp; Alexa与AWS IoT的集成\n环境配置：在 Windows 中配置 Docker 镜像 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/iot/docker/",
	"title": "IoT 开发环境： 可编译 C 的 Docker 镜像",
	"tags": [],
	"description": "",
	"content": " 该指南包含在 Windows 环境安装 Docker，使用 Dockerfile 配置环境以及相关操作介绍。\n步骤一 在本地安装 Docker 在Docker官网下载 Windows 端安装包\n安装后，在开始菜单输入cmd打开命令窗口，输入\ndocker --version  检查是否安装完毕。\n在桌面点击图标，等待加载完成，右下角图标显示：\n步骤二 配置 Docker Docker 中的镜像文件可以通过命令行下载、导入本地镜像文件等方法进行配置。\n（1） 方法一 Dockerfile 配置带 gcc 编译器的 ubuntu 系统。\nFROM ubuntu ENV DEBIAN_FRONTEND noninteractive RUN apt-get update \u0026amp;\u0026amp; \\ apt-get -y install gcc mono-mcs \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/*  您可使用上述文本创建 Dockerfile 文件，通过以下命令调用它创建该 docker 镜像：\ndocker build -t [your image] [directory of the dockerfile]  docker build 命令将读取指定路径下(包括子目录)的 Dockerfile，并将该路径下的所有内容发送给Docker服务端，由服务端来创建镜像。\n（2）方法二 加载 ubuntu 系统的镜像\n调用下述代码下载ubuntu 镜像。\ndocker pull ubuntu  创建 docker 后，您可通过命令行：\ndocker image ls  查看本机安装的 docker 列表\n到此处您的 docker 已经配置完毕，您可以新建并启动镜像，开始编译 C 程序了。\n依次执行下述命令配置编译环境\napt-get update apt-get -y install gcc mono-mcs rm -rf /var/lib/apt/lists  使用下述命令可以将本机文件拷贝进容器\n输入 gcc main.c 后生成 a.out 执行文件\n您也可使用 gcc main.c -o main 命令直接生成可执行文件\nDocker 相关操作 1、Docker导入本地镜像\n若需要导入本地的镜像，可使用\ndocker import  注意镜像文件必须是tar.gz类型文件。\n2、删除镜像\n若需删除某些镜像。使用如下的命令：\ndocker rmi -f image_id  -f：表示强制删除镜像；image_id：镜像id\n3、映射端口\n若docker需要使用本机端口使用-p或-P参数来指定端口映射，使用-P(大写P)标记时，Docker会随机映射一个端口到内部容器开放的网络端口。\n$ 映射 docker run -d --name [] -P []:latest docker run -itd --name [] -p 80:80 []:latest $ 查询 docker ps  4、创建数据卷\n使用-v参数也可以指定挂载一个本地目录到容器中去作为数据卷（推荐方式）。\ndocker run -itd --name [] -v [本地目录]:[容器内目录] []:latest  5、启动容器\n启动一个已经暂停的容器时，可使用命令：\ndocker start [CONTAINER ID]\n6、终止容器\n停止一个正在运行中的容器。使用命令：\ndocker stop [-t|--time[=10]] [CONTAINER...]  执行了 docker stop 命令之后，docker 首先会向容器发送 SIGTERM 信号，等待一段时间（默认10秒）后，再发送 SIGKILL 信号来终止容器。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/migration/bjstozhy/",
	"title": "AWS服务迁移：从北京区到到宁夏",
	"tags": [],
	"description": "",
	"content": " 本指南将逐步介绍如何将您在 AWS 北京区域的服务迁移到宁夏区域，涵括范围如下：\n EC2 \u0026amp; AMI EBS S3 RDS Redis DynamoDB  1. 将 EC2 \u0026amp; AMI 服务从 BJS 迁移至 ZHY 本部分将逐步介绍如何将 EC2 实例导出为 AMI，并从北京迁移到宁夏区。\n步骤一 创建AMI  在 EC2 控制台中，在左侧选择栏中点击 Instances，选中您希望迁移的实例，右键选择 Image -\u0026gt; Create Image。   也可选择使用 CLI 命令行进行操作。\naws ec2 create-image \u0026ndash;instance-id [your instance id] \u0026ndash;name [your AMI name]\n 在控制台左侧选择 Images-\u0026gt; AMIs 检查已创建的 AMI。\n  步骤二 将 AMI 部署在您希望转移的地区  在 EC2 控制台中，右击刚创建的 AMI，选择 Copy AMI。   在 Destination region 部分选择您希望迁移的目标可用区。   您也可选择使用 AWS CLI 命令行创建 AMI。\naws \u0026ndash;region cn-northwest-1 ec2 copy-image \u0026ndash;source-region cn-north-1 \u0026ndash;source-image-id [your image id] \u0026ndash;name [your AMI name]\n 在控制台左侧选择栏，选择 Images-\u0026gt; AMIs 查看刚刚创建的 AMI,右键点击 Launch 部署您的 EC2 服务。\n  2. 将EBS服务从BJS迁移至ZHY 本部分将逐步介绍如何将 EBS 卷从北京迁移到宁夏区。\n步骤一 创建快照  为对应 EBS 卷创建实例。右击卷名称，选择 Create Snapshot。  步骤二 迁移到其他可用区  在控制台左侧选择栏点击 Snapshots, 选中您刚创建的实例，点击 Action -\u0026gt; Copy 复制快照到其他可用区。   在目标区域中选择宁夏，点击 Copy。   创建完成后，请将控制台切换到宁夏区，可以查看上一步骤中复制的快照，右击快照选择 Create Volume 部署 EBS。  3. 将 RDS 服务从 BJS 迁移至ZHY 本实例使用 RDS 的 MySQL 作为案例，您也可以迁移 RDS 中其他数据库服务。\n（1）方案一 创建快照部署到其他区域\n该方法使用 RDS 数据库在宁夏区创建快照，并重新部署快照，实例与快照之间转换时间较长，若您的数据库较小，可选用该方案。\n 在RDS控制台选中您希望转移的实例，依次选择 Action -\u0026gt; Take a DB snapshot。   填写快照名称。   在左侧导航栏中选择 Snapshot，右击刚创建的快照，选择 copy snapshot 复制 RDS 服务快照。   选择宁夏区作为您复制快照的目标区域。   您可以在宁夏区的 snapshot 中查看上一步复制的快照，并在宁夏区重新部署该服务。  （2）方案二 基于 BJS Master Node 迁移数据\n使用 RDS 平台中 Read Replica 功能将数据拷贝到宁夏区，步骤如下：\n 在北京区点击您希望迁移的数据库，进入页面后，选择 Instance actions -\u0026gt; Create read replica。   选择将复制实例放在宁夏区，Multi-AZ deployment 选择 Yes。   按需求配置复制实例其他参数。\n 选择 Create read replica，等待数据库部署完毕。\n 监控数据库实例的 Replication 状态，等待滞后时间 Lag 变为 0。\n   选择 Instance actions -\u0026gt; Promote Read Replica。将其升为主库。  注意：\n宁夏区 MySQL 最低版本为 5.6.29，若您北京区的 MySQL 版本低于宁夏区，需要选择 Modify 升级数据库。\n若您的数据库有其他 Read Replica, 需先升级复制项。\n4. 将 S3 服务从 BJS 迁移至 ZHY 本部分将逐步介绍如何将 S3 服务迁移到新的可用区，您有以下两种迁移方案：\n 在宁夏区（目标区）创建一个新的 S3 桶，将数据拷贝到该桶中。 删除原数据桶并在宁夏区（目标区）重新创建同名 S3 桶，该方案需要一个临时桶作为转移媒介。\n注意:该方法需要在删除旧 S3 桶后等待24小时至名称再次有效。\n  （1）创建新的S3桶  在 S3 控制台中，点击 Create Bucket，选择宁夏作为桶的可用区，在 Copy settings from an existing bucket 选项中，选择您欲做迁移的 S3 桶，可同步两个桶的配置。   在 CLI 端运行以下命令行，开始复制桶内文件。\naws s3 sync s3://SOURCE_BUCKET_NAME s3://NEW_BUCKET_NAME\n  （2）重新创建S3桶  创建临时桶，步骤参见（1）。 在 CLI 端逐步运行以下命令行，将旧 S3 桶中的内容存入临时桶。\naws s3 sync s3://foobucket s3://tmpbucket\n 在控制台中旧 S3 桶删除，等待24小时后该命名重新生效。\n 重新在宁夏区注册同名 S3 桶。\n 在 CLI 端逐步运行以下命令行，将临时桶中的文件存入目标桶。\naws s3 sync s3://tmpbucket s3://foobucket\n  5. 将 ElastiCache 服务从 BJS 迁移至 ZHY 本例中将逐步介绍如何将 ElastiCache 服务迁移到另一可用区，本实例使用 Redis 作为案例。\n步骤一 备份 Redis 服务到S3  创建备份前请停止写入操作。\n 在控制台选中希望迁移的 Redis 服务，点击上方的 Backup 按钮创建备份。\n 在控制台左侧选择栏中点击 Backups 选项，查看您刚创建的备份。\n 创建一个 S3 桶用来存储 ElastiCache 备份。 注意：桶的可用区需要和 ElastiCache 相同。\n 登录 AWS S3 控制台，并创建新的 S3 桶，请参考本指南 4 创建桶。\n 依次选择 Permissions -\u0026gt; Access Control List。\n 在 Access for other AWS accounts 下, 选择 + Add account。\n 在窗口内添加地区的 canonical id。\nBJD (Beijing) 和 ZHY (Ningxia) :\nb14d6a125bdf69854ed8ef2e71d8a20b7c490f252229b806e514966e490b8d83\n 下述选项勾选Yes: List objects Write objects Read bucket permissions\n   选择 Save，授权 ElastiCache 读写 S3 桶内文件.  步骤二 将备份部署到宁夏区  参考 4 将位于北京区的 S3 桶中文件迁移至宁夏区，或下载备份文件，上传到您位于宁夏的 S3 桶中。\n 参考步骤一，在宁夏区 S3 桶添加 ElastiCache 读文件权限。\n 在宁夏区建立新的 Redis 服务。\n 在 Import data to cluster 项中填入位于宁夏 S3 桶中的备份文件路径。\n  6. 将 DynamoDB 服务从 BJS 迁移至 ZHY 将您的 DynamoDB 服务迁移到宁夏区。\n（1）使用自定义 API\n您可以使用 API 将 BJS 的数据转移到 ZHY，您可根据需要编写程序配置参数，示例程序如下：\nfrom __future__ import print_function import boto3 import argparse def replicate(table_name, existing_region, new_region, new_table_name): \u0026quot;\u0026quot;\u0026quot; Replicate table in new region. Creates a new table with existing KeySchema and AttributeDefinitions default read and write capacity units are set to 5. Change it as required. Parameters ---------- table_name: string Name of the existing table to be replicated. existing_region: string Region in which the table is present. new_region: string Region in which the table needs to be replicated. new_table_name: string Name for the new table to be created, if not given existing table name is used. \u0026quot;\u0026quot;\u0026quot; existing_table = boto3.resource( 'dynamodb', region_name=existing_region).Table(table_name) items = existing_table.scan()['Items'] dynamodb = boto3.resource('dynamodb', region_name=new_region) print(\u0026quot;Creating table '{0}' in region '{1}'\u0026quot;.format( new_table_name, new_region)) table = dynamodb.create_table( TableName=new_table_name, KeySchema=existing_table.key_schema, AttributeDefinitions=existing_table.attribute_definitions, ProvisionedThroughput={ 'ReadCapacityUnits': 5, 'WriteCapacityUnits': 5 }) print(\u0026quot;Table status:\u0026quot;, table.table_status) table.wait_until_exists() table.reload() print(\u0026quot;Table status:\u0026quot;, table.table_status) print(\u0026quot;Updating table with data...\u0026quot;) if table.table_status == 'ACTIVE': for item in items: response = table.put_item(Item=item) print(\u0026quot;PutItem status:\u0026quot;, response['ResponseMetadata']['HTTPStatusCode']) print(\u0026quot;Total items created:\u0026quot;, table.scan()['Count']) if __name__ == \u0026quot;__main__\u0026quot;: parser = argparse.ArgumentParser() parser.add_argument( '-t', '--table_name', type=str, required=True, help=\u0026quot;Name of the table to be replicated in new region\u0026quot;) parser.add_argument( '-r', '--region', type=str, required=True, help=\u0026quot;Region in which the table is present\u0026quot;) parser.add_argument( '-nr', '--new_region', type=str, required=True, help=\u0026quot;Region in which the table needs to be replicated\u0026quot;) parser.add_argument( '-nt', '--new_table_name', type=str, help=\u0026quot;Name for the new table [Optional], Old table name will be used\u0026quot;) args = parser.parse_args() if args.new_table_name is None: args.new_table_name = args.table_name replicate(args.table_name, args.region, args.new_region, args.new_table_name)  您可以在终端执行如下代码：\npython transferDynamoDB.py -t [source table] -r [source region] -nr [destination region]  （2）使用 EMR Hive 中转迁移数据到宁夏\n使用 Amazon EMR 服务创建集群，使用 EMR Hive 将 BJS 数据迁移到 ZHY。\n 在 EMR 控制台创建集群。\n 使用 SSH 连接主机。\n 登入 Hive\n 在 Hive 创建2个 External table，location 分别指向 BJS 和 ZHY。\nCREATE EXTERNAL TABLE hive_table (hive_column1_name hive_column1_datatype, hive_column2_name hive_column2_datatype\u0026hellip;)\nSTORED BY \u0026lsquo;org.apache.hadoop.hive.dynamodb.DynamoDBStorageHandler\u0026rsquo;\nTBLPROPERTIES ( \u0026ldquo;dynamodb.table.name\u0026rdquo; = \u0026ldquo;dynamodb_table\u0026rdquo;, \u0026ldquo;dynamodb.column.mapping\u0026rdquo; = \u0026ldquo;hive_column1_name:dynamodb_attribute1_name,hive_column2_name:dynamodb_attribute2_name\u0026hellip;\u0026rdquo; );\n 使用 query 将 BJS 数据复制到 ZHY。\n注意：可使用 insert into 进行复制，以免覆盖原数据。\n  数据库迁移完毕后，请及时更改服务器配置。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/migration/",
	"title": "Migration",
	"tags": [],
	"description": "",
	"content": " 使用 SMS \u0026amp; VM-import 导入 VM 指导 将域名从GoDaddy迁移至Route 53 使用 AWS DMS 迁移 MongoDB 到 S3 AWS服务迁移：从北京区到到宁夏区 基于Amazon ECS的国内外文件同步系统解决方案 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/migration/dms-mongo-to-s3/",
	"title": "使用 AWS DMS 迁移 MongoDB 到 S3",
	"tags": [],
	"description": "",
	"content": " 概述 DMS 的迁移部署耗时约十分钟.\n概念解释  源: 您需要迁移数据的来源, 在这里的源为您的 MongoDB 数据库\n 目标: 您需要迁移数据的目的地, 在这里目标为您的 S3 桶\n 复制实例: 您可以将复制实例理解为一台虚拟主机. AWS DMS 执行数据迁移时, 会先从源数据库中读取数据到复制实例, 再对数据进行相应的调整( 如格式转换)后, 最终将数据载入到目标数据库\n   持续复制( 也叫做数据捕获, CDC ): 在实际生产中, 当源数据库中数据发生改变时, 我们需要在目标数据库中也应用这些改变, 如若达到这种目的, 可以使用CDC.  特别的, CDC 只会读取您改变的那一部分数据, 即增量迁移\n注意事项  MongoDB 版本: 若将 MongoDB 作为源, 则 MongoDB 的版本必须为 2.6.x 或 3.x 若要使用 CDC 功能, AWS DMS 必须要具有对 oplog 的访问权限, 因此请确保您的 MongoDB 具有可用的副本集. 有关更多的信息, 请参阅 MongoDB 文档  迁移步骤  重要\n在本文中所涉及参数设置仅为演示作用\n通常情况下, 您都需要根据您的实际情况, 设置适合您自己的参数\n更多的参数细节请参考 DMS 最佳实践\n 配置 IAM 角色  在 IAM 导航中选择角色, 并点击创建角色   在创建角色面板的选择受信任实体的类型中选择 AWS 产品, 在选择将使用此角色的服务中选择 DMS, 最后点击下一步   在附加权限策略中搜索 EC2, 并勾选 AmazonEC2FullAccess. 再搜索 S3, 并勾选 AmazonS3FullAccess, 再点击下一步   在审核页面中, 自定义您的角色名称( 本文中设置为了dms-mongo-s3 )及角色描述( 可选 ), 最后点击创建角色   在完成页面点击角色名  在摘要页面中记录下角色 ARN\n配置复制实例  在 DMS 导航中选择复制实例, 并选择创建复制实例   在创建复制实例页面, 按以下内容配置, 未说明的配置项即采用默认配置\n 名称: 用户自定义, 本文采用dms-mongo-s3 描述: 用自定义 实例类: 请根据您的数据情况选择合适的实例类型, 本文中采用为 dms.t2.large VPC: 请采用能连接到您 MongoDB 数据库所在的 VPC 多可用区部署: 请根据您的需要选择是否启用, 本文采用否 公开访问: 请根据您的需要选择是否启用, 本文采用是   再点开高级\n VPC 安全组: 选择合适的安全组, 确保您的复制实例能连接到您的 MongoDB 数据库   点击创建复制实例  配置源端 在配置源端前, 请确保您的 MongoDB 已满足使用 AWS DMS 的条件\n 在 DMS 导航中选择终端节点, 并选择创建终端节点   在创建终端节点, 按以下内容配置, 未说明的配置项即采用默认配置\n 终端节点类型: 源 终端节点标识符: 自定义, 本文中采用 dms-mongo 源引擎: mongodb 服务器名称: \u0026lt;您 MongoDB 数据库所在的 IP 地址\u0026gt; 端口: \u0026lt;您 MongoDB 数据库的的端口号\u0026gt; 身份验证模式: 若您的数据库需要用户身份验证, 请选择 password, 然后填写以下四项内容 用户名: 请填入具有合适权限 的MongoDB 用户的用户名, 关于将 MongoDB 用作 AWS DMS 的源时所需的权限, 请参考将 MongoDB 作为 AWS DMS 源 密码: 您 MongoDB用户对应的密码 身份验证来源: 您 MongoDB用户所在的身份库, 本文中为 MongoDB 默认的身份库admin 数据库名称: 您要迁移的数据库名称 元数据模式: document    在测试终端节点连接中,按以下内容配置,并选择运行测试\n VPC: 选择您在配置复制实例这一步骤中创建的复制实例所在的VPC 复制实例: 选择您在配置复制实例这一步骤中创建的复制实例    在点击运行测试完成后, 等待一段时间后, 如若配置成功, 则会出现已成功测试连接的字样, 之后点击 Save  配置目标端 请先在 S3 中建立您需要存放迁移后数据的桶, 本文所使用的桶为 dms-mongo-s3\n 在 DMS 导航中选择终端节点, 并选择创建终端节点   在创建终端节点, 按以下内容配置, 未说明的配置项即采用默认配置\n 终端节点类型: 源 终端节点标识符: 自定义, 本文中采用 dms-s3 目标引擎: s3 服务访问角色 ARN: 您在配置 IAM 角色这一步骤中创建的角色的 ARN 存储桶名称: 存放迁移后数据的桶的名称, 本文为 dms-mongo-s3   在测试终端节点连接下\n VPC: 选择您在配置复制实例这一步骤中创建的复制实例所在的VPC 复制实例: 选择您在配置复制实例这一步骤中创建的复制实例  点击运行测试\n 在点击运行测试完成后, 等待一段时间后, 如若配置成功, 则会出现已成功测试连接的字样, 之后点击 Save  发起任务  在 DMS 导航中选择任务, 并选择创建任务   在创建任务页面, 按以下内容配置, 未说明的配置项即采用默认配置\n 任务名称: 用户自定义, 这里采用 dms-mongo-s3 复制实例: 选择您在配置复制实例这一步中创建的复制实例 源终端节点: 选择您在配置源端中创建的源 目标端节点: 选择您在配置目标端中创建的目标 迁移类型: 迁移现有数据并复制持续更改 在创建时启动任务: 勾选 启用日志记录: 勾选(十分建议您勾选此项)    在表映像块下,输入以下内容, 并选择添加选择规则\n 架构名称是: 选择输入架构 架构名称: %    点击创建任务  迁移结果 当您按照以上步骤中完成所有的配置后,若出现以下内容, 则意味着您开启了一个具有增量迁移功能的从 MongoDB 到 S3 的数据迁移任务.\n此任务不仅会在第一次启动时从 MongoDB 迁移所有的数据到 S3, 还会在之后每当您在 MongoDB中的数据有所改变时, 把改变情况也反应到 S3\nMongoDB 中的数据 本文所使用的 MongoDB 数据库中含有两张表, BookSpider 与 test\n BookSpider 中的表结构   test 中的表结构  未触发持续复制的迁移结果 当迁移完成后, 如果源数据库中的数据未发生改变, 则意味不会触发 CDC\n此时 S3 中目录结构为\n Scrapy_data(文件夹, 与源数据库同名)  BookSpider(文件夹, 其中一个表同名) LOAD00000001.csv test( 文件夹, 与另一个表同名) LOAD00000001.csv   这两个 csv 文件即保存了 MongoDB 中对应表的所有的数据信息, 选取 BookSpider 表的LOAD00000001.csv\n如上图, 所有的数据都以 json 格式保存了下来\n触发了持续复制后的迁移结果 我们对 BookSpider 表增加一条数据, 修改一条数据, 再删除一条数据, 使其能够触发 CDC\n 增   改   删  此时打开 S3, 其目录结构变为了\n Scrapy_data  BookSpider LOAD00000001.csv 20180902-104149271.csv(新增) 20180902-104505261.csv(新增) test( 文件夹, 与另一个表同名) LOAD00000001.csv   打开两个文件新增的 csv 文件\n 20180902-104505261.csv   20180902-104149271.csv  可以看到, 三个改变都被记录了下来, 切前面多了 U D I 三个字母, 这意味着这三条操作分别为 Update, Delete,Insert\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/migration/sms_vm-import/",
	"title": "使用 SMS &amp; VM-import 导入 VM 指导",
	"tags": [],
	"description": "",
	"content": " Part 1: 使用SMS导入VM 本指导将逐步描述如何使用 AWS Server Migration Service (SMS)服务将 VMware vSphere 的虚拟机映像自动迁移到 Amazon AWS。\n步骤一 添加IAM用户 首先需要在控制台添加 IAM ，步骤如下：\n IAM 控制台中选择 Roles 和 Create new role。 在 Search role type 页面上，找到 SMS 并选择 Select。 在 Attach Policy 页面上，选择 ServerMigrationServiceRole，然后选择 Next Step。 在 Set role name and review 页面上，键入 Role name。\n 选择 Create role。您现在应该能够在可用角色列表中看到该角色。  步骤二 在 VMware 上安装服务器迁移连接器 介绍如何使用 AWS SMS 将 VM 从 VMware 迁移到 Amazon EC2。此信息仅适用于本地 VMware 环境中的 VM。\n第一步：为 VMware 环境设置连接器  注意\n本步骤主要为 vCenter 的设置，该功能在通常情况下（ 只上传单个镜像）并不需要使用。\n若您确认您没有使用该功能的必要则可跳过该步骤，直接从 第二步：配置连接器 开始。\n  设置 vCenter 服务账户。在 vSphere Client 点击 Home -\u0026gt; Role -\u0026gt; Add Role 创建一个 vCenter 用户。 右击创建的用户，点击 Edit Role，在 vCenter 中创建具有以下权限的角色：\n Datastore -\u0026gt; Browse datastore and Low level file operations (Datastore.Browse 和 Datastore.FileManagement) Host -\u0026gt; Configuration -\u0026gt; System Management (Host.Config.SystemManagement) vApp -\u0026gt; Export (VApp.Export) Virtual Machine -\u0026gt; Snapshot management -\u0026gt; Create snapshot and Remove Snapshot (VirtualMachine.State.CreateSnapshot 和 VirtualMachine.State.RemoveSnapshot)    将此 vCenter 角色分配给连接器的服务账户，添加针对要迁移的 VM 的数据中心的传播权限。\n  第二步：配置连接器  在控制台中打开 AWS Server Migration，选择 Connectors -\u0026gt; SMS Connector setup guide。\n 在 AWS Server Migration Connector setup 页面上，选择 Download OVA 下载连接器。\n 在 vSphere 客户端点击 File -\u0026gt; Deploy OVF Template，将下载的连接器 OVA 部署到 VMware 环境中。\n 打开连接器的虚拟机控制台并使用密码 ec2pass 以 ec2-user 身份进行登录。在系统提示时提供新密码。\n 获取连接器的 IP 地址，如下所示：\nCurrent network configuration: DHCP IP: 192.0.2.100 Netmask: 255.255.254.0 Gateway: 192.0.2.1 DNS server 1: 192.0.2.200 DNS server 2: 192.0.2.201 DNS suffix search list: subdomain.example.com Web proxy: not configured Reconfigure your network: 1. Renew or acquire a DHCP lease 2. Set up a static IP 3. Set up a web proxy for AWS communication 4. Set up a DNS suffix search list 5. Exit Please enter your option [1-5]:  在连接器的网络配置菜单中，配置 DNS 后缀搜索列表中的域后缀值。\n 在 Web 浏览器中，通过 IP 地址 (https://ip-address-of-connector/) 访问连接器 VM，在页面选择 Get started now。\n 阅读许可协议，选中复选框，然后选择 Next。\n 为连接器创建密码。\n 选择 Upload logs automatically 和 服务器迁移连接器 auto-upgrade。\n 对于 AWS Region，从列表中选择您所处区域。对于 AWS Credentials，输入您的 AWS 账户权限中创建的 IAM Credentials。选择 Next。\n 对于 vCenter Service Account，输入步骤 3 中的 vCenter 主机名、用户名和密码。选择 Next。\n 接受 vCenter 证书后，完成注册，然后查看连接器配置控制面板。\n 验证 Connectors 页面中是否显示您已注册的连接器。\n  第三步：使用 AWS SMS 控制台复制 VM  如尚未导入目录，请选择 Servers -\u0026gt; Import server catalog。如需添加的新服务器，请选择 Re-import server catalog。 选择要复制的服务器，然后选择 Create replication job。\n 在 Configure server -\u0026gt; specific settings 页面上的 License type 列中，选择要从复制作业创建的 AMI 的许可类型。选择 Auto 时 AWS SMS 会自行选择适当的许可。注意，Linux 服务器只能使用自带许可 (BYOL)，Windows 服务器可以使用 AWS 提供的许可或 BYOL。 点击 Next。\n 在 Configure replication job settings 页面上，有以下设置可用：\n Replication job type - replicate server every interval 选项按您从菜单提供的间隔创建新的 AMI，创建一个重复的复制过程。 One-time migration 选项会触发服务器单个复制。 Start replication run - 可配置复制行为为立即开始或在未来 30 天内的某一日期和时间开始。日期和时间设置会参考浏览器的本地时间。 IAM service role - 提供您之前创建的 IAM 服务角色。 Description - 提供复制运行的描述。(可选) Enable automatic AMI deletion - 当复制 AMI 数量超出数字时删除较早的复制 AMI。 启用通知 - Amazon Simple Notification Service (Amazon SNS) 会在复制作业完成、失败或被删除时通知列表中的收件人。  选择 Next。\n 在“Review”页面上，检查您的设置。如果所有设置均正确，请选择 Create。要更改设置，请选择 Previous。\n  第四步： 监控和修改服务器复制作业  在 AWS SMS 控制台中，点击 Replication jobs 可查看所有复制作业。 选择其中一个复制作业，在下方的窗格中查看详细信息。Job details 选项卡显示当前复制运行的信息。Run history 选项卡显示有关选定复制作业的所有复制运行的详细信息。\n 如更改作业参数，请在 Replication jobs 页面上选择一个作业，点击 Actions -\u0026gt; Edit replication job。在 Edit configuration job 表单中输入新信息后，选择 Save 以提交您的更改。\n  第五步： 关闭复制  如需在复制完服务器后删除复制作业创建的其他服务。请在 Replication jobs 中选择对应作业，点击 Actions -\u0026gt; Delete replication jobs。在确认窗口中，选择 Delete。该操作不会删除创建的AMI。 如需清除服务器目录，请选择 Servers -\u0026gt; Clear server catalog。 如需取消连接器关联，请点击 Connectors，选择要取消关联的连接器。在其信息部分的右上角点击 Disassociate，在确认窗口中选择 Disassociate。  Part 2: 使用vm-import导入您的VM 本指导将逐步描述如何从 VM 中导出虚拟系统，使用 AWS Command Line Interface(AWS CLI) 或 API 工具将其导入 Amazon EC2。在开始操作前，请确保您的电脑中已经安装有 AWS CLI （请参考AWS CML用户指南）。\n步骤一 配置AWS CLI 安装客户端后，请在 AWS 控制台中选择 IAM User，创建安全证书并下载访问安全密钥，根据 AWS Access Key 和 AWS Secret Access Key 配置帐户。\n步骤二 配置并导出VM 在导出前，需确保 VM 具有以下几种配置：\nWindows系统：\n 启用 Remote Desktop (RDP) 以进行远程访问。 请确保该主机防火墙 (Windows 防火墙或类似防火墙) 允许访问 RDP。 确保管理员账户和所有其他用户账户均有密码，否则导入可能失败。 在 VM 上安装适当的 .NET Framework 版本。请注意，如果需要，系统会自动在您的 VM 上安装 .NET Framework 4.5 或更高版本。 在您的 Windows VM 上禁用 Autologon。 设置 RealTimeIsUniversal 注册表项。有关更多信息，请参阅 Amazon EC2 用户指南（适用于 Windows 实例） 中的设置时间。  Linux系统：\n 在VM中启用SSH远程访问，并保证VM防火墙允许外部访问VM。虽然允许基于密码的SSH，但为安全起见，建议使用公共密钥登录。 在VM中配置一个非root用户。（可选） 确保 Linux VM 将 GRUB（传统 GRUB）或 GRUB 2 作为其启动加载程序。 确保 Linux VM 使用下列根文件系统之一：EXT2、EXT3、EXT4、Btrfs、JFS 或 XFS。 关闭所有反病毒软件，从 VMware 虚拟机上卸载 VMware 工具。 保持网络设置为 DHCP 而不是静态 IP 地址。 导入的 Linux VM使用 64 位映像  完成导入准备工作后可以从虚拟环境中将 VM 导出。\nAWS支持四种格式的磁盘：开放虚拟化存档 (OVA)、虚拟机磁盘 (VMDK)、虚拟硬盘 (VHD/VHDX) 和原始格式。您也可以选择将开放虚拟化格式 (OVF)作为导出格式，OVF通常包含一个或多个 VMDK、VHD 或 VHDX 文件。\n有关更多信息，请参阅您的虚拟化环境的文档。例如： - VMware - VMware 网站上的导出 OVF 模板 - Citrix - Citrix 网站上的将 VM 导出为 OVF/OVA - Microsoft Hyper-V - Microsoft 网站上的导出和导入虚拟机概览\n本示例中我们使用VirualBox，该应用软件是一款小巧精悍、功能齐全的免费应用软件，且支持导出OVF/OVA格式的VM。\n导出VM时，在VirualBox主界面打开File-\u0026gt;Export Appliance，选择需要导出的虚拟机，点击Next。 选择导出配置，这里可以选择OVF/OVA两种格式，并选择保存地址。\n接下来对导出的VM添加说明信息后，就可以导出了，这里大约需要等待3分钟。\n步骤三 将VM作为映像导入 您可以使用 VM Import/Export 将虚拟机 (VM) 映像作为 Amazon 系统映像 (AMI) 从虚拟化环境导入到 Amazon EC2 中，并用于启动实例。随后也可以将 VM 映像从实例导回到虚拟化环境中。\n1. 创建VM import服务角色 VM Import 需要一个角色在您的账户中执行特定的操作，例如：从 Amazon S3 存储桶下载磁盘映像\n上传 ova 镜像至S3存储桶 请参考如何向 S3 存储桶添加对象\n创建服务角色  利用以下策略创建名为 trust-policy.json 的文件。\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [{ \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;Service\u0026quot;: \u0026quot;vmie.amazonaws.com\u0026quot; }, \u0026quot;Action\u0026quot;: \u0026quot;sts:AssumeRole\u0026quot;, \u0026quot;Condition\u0026quot;: { \u0026quot;StringEquals\u0026quot;:{ \u0026quot;sts:ExternalId\u0026quot;: \u0026quot;vmimport\u0026quot; } } }] }  使用 create-role 命令创建名为 vmimport 的角色，并向 VM Import/Export 提供对该角色的访问权。请确保指定 trust-policy.json 文件的完整路径，并且为路径添加 file:// 前缀。\naws iam create-role --role-name vmimport --assume-role-policy-document file://trust-policy.json  创建名为 role-policy.json 的文件并添加下面的策略，其中，请将\u0026lt;disk-image-file-bucket\u0026gt; 替换为存储ova映像的S3存储桶，这里需注意，如果您在中国区，请将 Resource 中 arn:aws:s3 更改为 arn:aws-cn:s3。\n{ \u0026quot;Version\u0026quot;:\u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;:[{ \u0026quot;Effect\u0026quot;:\u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;:[ \u0026quot;s3:GetBucketLocation\u0026quot;, \u0026quot;s3:GetObject\u0026quot;, \u0026quot;s3:ListBucket\u0026quot; ], \u0026quot;Resource\u0026quot;:[ \u0026quot;arn:aws:s3:::\u0026lt;disk-image-file-bucket\u0026gt;\u0026quot;, \u0026quot;arn:aws:s3:::\u0026lt;disk-image-file-bucket\u0026gt;/*\u0026quot; ] }, { \u0026quot;Effect\u0026quot;:\u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;:[ \u0026quot;ec2:ModifySnapshotAttribute\u0026quot;, \u0026quot;ec2:CopySnapshot\u0026quot;, \u0026quot;ec2:RegisterImage\u0026quot;, \u0026quot;ec2:Describe*\u0026quot; ], \u0026quot;Resource\u0026quot;:\u0026quot;*\u0026quot; }] }  使用下面的 put-role-policy 命令将策略挂载到之前创建的角色。\naws iam put-role-policy --role-name vmimport --policy-name vmimport --policy-document file://role-policy.json   2. 导入映像任务  创建名为containers.json的文件。其中，\u0026lt;my-import-bucket\u0026gt;为您上传 ova 镜像的 S3 桶的名称，\u0026lt;vms/my-windows-2008-vm.ova\u0026gt; 为您上传的 ova 镜像在 S3 桶中的地址。\n[{ \u0026quot;Description\u0026quot;: \u0026quot;Windows 2008 OVA\u0026quot;, \u0026quot;Format\u0026quot;: \u0026quot;ova\u0026quot;, \u0026quot;UserBucket\u0026quot;: { \u0026quot;S3Bucket\u0026quot;: \u0026quot;\u0026lt;my-import-bucket\u0026gt;\u0026quot;, \u0026quot;S3Key\u0026quot;: \u0026quot;\u0026lt;vms/my-windows-2008-vm.ova\u0026gt;\u0026quot; } }]   导入OVA。\naws ec2 import-image --description \u0026quot; Centos 7.0 \u0026quot; --disk-containers file://containers.json   记录下输出信息中的 ImportTaskId\n  3. 检查您的导入映像任务的状态 请根据上一步保留的 ImportTaskId 值自行替换该值，即可查询该任务的情况。\naws ec2 describe-import-image-tasks --cli-input-json \u0026quot;{ \\\u0026quot;ImportTaskIds\\\u0026quot;: [\\\u0026quot;import-ami-fggrs8es\\\u0026quot;], \\\u0026quot;NextToken\\\u0026quot;: \\\u0026quot;abc\\\u0026quot;, \\\u0026quot;MaxResults\\\u0026quot;: 10 } \u0026quot;  上述命令会根据 AWS 的处理进度，返回查询任务响应中的Status，依次为“Pending”、“Converting”、“Updating”、“Updated”、“Preparing AMI”等。整个的处理过程持续10+分钟，请耐心等待。\n参考资料  使用 VM Import/Export 将 VM 作为映像导入  "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/migration/s3_transmission/",
	"title": "基于Amazon ECS的国内外文件同步系统解决方案",
	"tags": [],
	"description": "",
	"content": " 很多跨国企业都会有数据同步的需求，这些大型文件主要是存储在S3桶上，通过console或者命令行的形式从本地上传至S3中。本文描述了一种基于容器化的，在Amazon ECS平台上搭建的、快速同步的且基于负载进行扩容和收缩的、通用的解决方案。\n解决方案概述 该方案如下图所示。 在该方案中，我们会启动以下资源： 1. 一个global的S3桶：用于global作为数据传输的源 2. 4个Lambda函数： 分别用于文件分片，容器的扩张与收缩，发送传输完成信号 3. 1个sqs队列：用于存储传输所用参数 4. 2个cloud watch警报： 监控sqs内消息数量，分别用于需要收缩和扩张容器 5. 一个ECS集群，一个服务和若干个task：用于搭载容器 6. 两个dynamoDB 表： T 和C。表T用于记录传输的uplaodID和分段，传输情况，表C用于记录每个片段的唯一标记值-etag。 7. 具有相应的权限的角色。\n \n在运行cloudformation之前需要您准备好： 国内：一个S3桶，用户的访问密钥 AccessId 和AccessKey 国外：一个VPC和其中的一个公有子网， EC2密钥对，用于接收信息的Email地址\n步骤：  用户在global bucket中成功上传文件。 触发lambda函数。Lambda函数会判断新文件的大小判断用哪种方式传输，当小于5M的时候会选择直接进行下载上传，当大于5M的时候会进行分段上传。 当确定用哪种方式进行传输之后会把相应的信息存储至sqs中，包括文件名称，uploadID, 分段情况等。 同时Lambda会将传输情况备份至dynamoDB表C中,表1用于记载传输情况。 容器运行在ecs集群中， SQS内的信息被ecs中的servces和task消耗， 我们为SQS设定了cloudwatch监控，用于根据负载实现容器的扩张和缩小。 我们创建了警报A 用于判断是否需要根据情况扩张和缩小容器的数量，当sqs内消息数量较大时会触发警报A 警报A会触发发送消息给SNS SNS接到消息之后会触发LambdaA LambdaA会调整容器的数量到10个，实现容器的扩张 当sqs内消息数量较小时会触发警报B 警报B会触发发送消息给SNS SNS接到消息之后会触发LambdaB LambdaB会调整容器的数量到1个，实现容器的收缩 容器会将下载的片段传至国内S3桶。 容器更改dynamo DB表C中的数据，更新已完成的片段数量 容器更改dynamo DB 表P，插入新的数据存入etag和uplaod id partnumber等信息。 当表C中已完成的片段数量和公有片段数量一致的时候会触发Lambda函数 函数搜索同一个uploadID的所有的片段的etag 并按partnumber排序，发送给国内的S3桶。S3桶在核对所有的etag之后进行片段组装，出现在国内的S3桶上。\n架构部署 登录 AWS 管理控制台并通过以下网址打开 AWS CloudFormation 控制台：https://console.aws.amazon.com/cloudformation。\n 如果这是新的 AWS CloudFormation 账户，请单击“Create New Stack”。否则，请单击“Create Stack”。\n 在模板部分，选择指定 Amazon S3 模板 URL\n 在 Specify Details 部分的 Name 字段中，输入堆栈名称。堆栈名中不得含有空格。\n 在 Specify Parameters (指定参数) 页上，您将看到模板的 Parameters 部分中的参数。 请按实际情况填写。\n 单击 Next (下一步)。\n 在这种情况下，我们不会添加任何标签。单击“Next”。作为密钥值对的标签可帮助您识别堆栈。\n 审查堆栈信息。如果满意该设置，则单击“Create ”。\n  "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/migration/transferdomainroute53/",
	"title": "将域名从GoDaddy迁移至Route 53",
	"tags": [],
	"description": "",
	"content": " 该指南将逐步介绍如何将 GoDaddy 的域名转移到 Amazon Route 53 服务，在开始前请确认以下几点：\n 您在该站点的域名已经注册60天以上。 请确认您的域名后缀（.com, .cn, .uk等）在亚马逊业务支持范围内查看可向 Amazon Route 53 注册的域。 部分顶级域名需更改参数，例如所有者名称。 请确保您注册该域名的网站具有转移域名的服务。  注：本实例中使用 GoDaddy 中注册的域名作为案例。\n迁移DNS服务 若您的域的DNS服务处于正在使用中，希望在流量不受影响下迁移域，请参考本节步骤，在迁移域名前将您的 DNS 服务迁移到 Route 53 中，如您的域的 DNS 服务处于空闲状态，或您的运营商迁移域名后也继续支持 DNS 服务，可跳过本部分，从步骤一开始。\n1. 从当前DNS服务提供商获取当前DNS配置文件（可选） 在 GoDaddy 登录后，点击需要迁移的域名右侧的 DNS 按钮，在弹出网页下方的 Advanced Features 下选择对应操作。您可使用该配置文件在 Route 53 中重新配置 DNS 服务。\n2. 创建托管区域 在Route 53中创建一个与您的域同名的托管区域，在该区中创建记录。Route 53 会自动为该域创建名称服务器（NS）和授权起始点（SOA）记录。步骤如下：\n创建托管区域 首先打开Route 53 服务控制台。\n 若您是首次使用Route 53, 请在 DNS Managment 下点击 Get Started Now。   在 Hosted Zones 中点击 Created Hosted Zone。 在该窗口中，输入您的域名，填写注释（可选）。 Type 选项保留默认值 Public Hosted Zone。 选择 Create。   创建记录 在您创建的托管区域中创建记录，定义您的域和子域的流量的路由规则。有以下三种方式供您选择：\n 1.导入区域文件   导入 DNS 区域文件自动创建标准 DNS 记录。 请参阅通过导入区域记录创建记录\n 2.在控制台单独创建记录   在控制台中创建记录。Route 53 支持同时创建别名记录和非别名记录。\n 选择路由策越 在别名和非别名记录之间做出选择 使用Amazon Route 53控制台创建记录\n 3.以编程方式创建记录\n  您可以使用某个 AWS 开发工具包、AWS CLI、适用于 Windows PowerShell 的 AWS 工具或 Route 53 API。\n减小TTL设置 TTL（生存时间）为 DNS 解析程序的缓存记录及使用缓存信息的时间。当 TTL信息过期时，解析程序会向域的 DNS 服务提供商查询最新消息，缩短 TTL 时间可以减小您在发现问题后的恢复时间。\nRoute 53 NS 的标准 TTL 默认设置为172800秒或2天，您可将其减小到15分钟左右。\n 登录 AWS 管理控制台并通过以下网址打开 Route 53 控制台：https://console.aws.amazon.com/route53/。\n 在导航窗格中选择 Hosted Zones。\n 选择托管区域的名称。\n 点击对应 NS 记录。\n 更改 TTL (Seconds) 的值。我们建议您指定一个介于 60 秒和 900 秒 (15 分钟) 之间的值。\n 选择 Save Record Set。\n  等待原TTL过期 若您的域正在使用中，则 DNS 解析程序将会缓存当前 DNS 服务提供商提供的名称服务器的名称。最长会保存近两天。为确保一次性完成 DNS 服务迁移，请在减小 TTL 后等待两天。两天后解析程序将获取当前名称服务器，并且获取您在指定的新 TTL 数值。\n更新当前DNS服务提供商NS记录 该步骤将配置 Amazon Route 53 作为域的 DNS 服务，更新当前 DNS 服务提供商的 NS 记录，请参考以下步骤：\n 在 Route 53 控制台中，获取您的托管区域的名称服务器：\n 登录 AWS 管理控制台并通过以下网址打开 Route 53 控制台：https://console.aws.amazon.com/route53/。\n 在导航窗格中，选择 Hosted zones。\n 在 Hosted zones 页面上，选择适用的托管区域的单选按钮 (而不是名称)。\n 记下列出的针对 Name Servers 的四个名称。\n    在 GoDaddy 更新托管区域的 NS 记录。进入 DNS Management 页面,更改 NameServer 部分。\n 记录当前托管区域的 NS 记录中的 NS 名称，用于保存记录。 添加您在上步中获取的四个 Route 53 NameServer 的名称。 点击 Save。    监控域的流量(可选) 更改后，您可以监控域的流量，确定未受影响后，继续下一个步骤。\n更改TTL时间 在 Hosted Zones 中选择托管区域的名称，点击 NS 记录，将 TTL 时间改为最大，我们建议更改为172800秒，点击 Save Record Set。\n将域注册转移到Amazon Route 53 现在您已将域的 DNS 服务转移到 Amazon Route 53，您可以继续将域注册商转为 Route 53。\n步骤一 在GoDaddy账户中解锁域名转换权限 登录 GoDaddy 网站，点击 My Products，选择对应域名下方的 Manage 进入 Domain Settings 界面。\n在该页面中找到 Additional Setting，点击 Domain lock 旁的 Edit。\n关闭 Domain lock，等待 GoDaddy 执行您的更改。完成后，您将收到一封来自 GoDaddy 的邮件，标题为 Domain Status Notification, 提示您修改完毕。\n步骤二 从 GoDaddy 或许授权码到 AWS 我们需要从 GoDaddy 获取授权码，授权 Route 53 获取该域名。该步骤需要在 AWS 控制台使用授权码提交域名迁移请求。\n同样在 Domain Setting 页面，在 Additional Settings 下面，点击 Get authorization code。\n您将收到一封邮件提示您获取授权码。\n步骤三 在Amazon Route 53 控制台提交迁移请求 进入 AWS 控制台，点击 Amazon Route 53。在 Domain 下方，点击 Registered Domains -\u0026gt; Transfer Domain。 输入域名并选择您域名的后缀。点击 Check。\n在弹出确认框勾选可选框。通常您需要将 DNS 解析服务迁移到 Route 53来保证服务正常运行。\n点击 Add to cart。\n可在该页面继续添加其他您希望迁移的域名。点击位于页面底部 Continue 提交。\n下一个页面中输入您 GoDaddy 账户的 Authorization code。 AWS 会询问如何管理您的 NS 服务。如果您已将 DNS 服务迁移到 Amazon Route 53，可选择第二个选项。\n点击 Continue 并填写注册信息表。您可以选择是否隐藏信息，如选择是，您的个人信息将仅被提供给 ICANN 用于注册。\n点击 Continue，并确认您填写的信息是否正确。如是，勾选下图中的选择框，并点击 Complete Purchase。\n步骤四 授权 Amazon Route 53 迁移域 完成上述操作后，您将看到您的域名处于 Pending Transfer 的状态。 AWS 将会给域的所有者发送一封邮件。点击该邮件中的链接，在弹出页面中选择 Yes，并点击 Submit。\n步骤五 在 GoDaddy 上通过迁移请求 当您完成步骤四后，GoDaddy 将会给您发送一封请求通过迁移的邮件。\n进入您的 GoDaddy 账户，依次选择 My Domains -\u0026gt; Pending transfer out 下面的 view details。\n选择您需要转移的域名，点击 Accept or Decline。\n在弹出页面选择 Accept，点击 OK。\n步骤六 完成迁移 在迁移结束后，您将收到 AWS 的邮件通知域名迁移成功。 Route 53 的 Registered domains 将会显示您已迁移的域名。\n备注 如您未提前迁移 DNS 服务，需等待48个小时。迁移您的域名注册商不会产生额外的时间开销。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/cicd/",
	"title": "CICD",
	"tags": [],
	"description": "",
	"content": " AWS 资源自动 Tag 方案 基于CodePipeline, ECS的cicd解决方案 基于jenkins的容器蓝绿部署解决方案 基于jenkins的java应用程序CICD解决方案 自动化监测 \u0026amp; 启动可用资源 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/cicd/codepipeline_ecs/",
	"title": "基于CodePipeline ECS的CICD解决方案",
	"tags": [],
	"description": "",
	"content": " 综述： 通过本文章，您可以通过AWS CodePipeline，AWS CodeBuild，AWS CodeCommit, AWS CloudFormation 来实现基于Amazon ECS的CICD方案。开发人员在AWS CodeCommit中提交的新版本代码，会自动触发代码获取，打包镜像，上传镜像仓库，创建新版本的任务定义和服务。\n所需组件  Code Commit：AWS CodeCommit 是由 Amazon Web Services 托管的版本控制服务，可让您在云中私下存储和管理资产（如文档、源代码和二进制文件）。 Docker：CodeBuild使用Docker container 运行构建过程中需要的应用程序。 Amazon EC2：作为ECS的容器宿主机集群。 Amazon VPC：服务所在的网络。 Amazon ECS：AWS托管的容器编排服务。 Amazon ECR：AWS 托管的容器镜像仓库。 AWS CodePipeline：AWS 托管的持续集成持续交付服务，可以快速可靠的更新应用程序和服务，集成支持GitHub，Jenkins等主流开源工具。 AWS CodeBuild：AWS 托管的构建服务，用于打包代码生成可部署的软件包。 AWS CloudFormation：批量创建和管理AWS资源的自动化脚本。  步骤 流程  开发者将一个新版本的代码工程提交到CodeCommit或者github 触发codepipeline 流程 Pipeline的Source阶段，检测到指定CodeCommit的repo/ github 有新版本的更新 从CodeCommit / github 上拉取工程代码 Pipeline的Build阶段，AWS CodeBuild将新版本的代码按照 buildspec 文件打包为jar包 将打包好的jar包上传到S3 上传到s3的jar包会作为下一步build的source Pipeline的Build阶段，上一部build结束之后会触发第二个构建步骤，本步骤将jar包打包成Docker镜像 将Docker镜像上传到ECR镜像仓库 ECR中的镜像会在下一步中作为容器镜像 Pipeline的Deploy阶段，AWS CodePipeline触发AWS CloudFormation，其定义了Amazon ECS的Task definition和service AWS CloudFormation创建新版本的Task definition关联到新版本的Docker镜像，并更新Service。Amazon ECS从Amazon ECR中取到新版本的Docker镜像，创建新的 Task definition和服务，完成服务的更新   搭建 基础设施 创建VPC，子网  打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。 在控制面板上，选择 Create VPC (创建 VPC)。  选择第一个选项，即 VPC with a Single Public Subnet，然后选择‘选择’。  保留其余默认设置，然后选择 Create VPC (创建 VPC)。\n安全组 创建 WebServerSG 安全组\n 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。\n 在导航窗格中，选择 Security Groups。\n 选择 Create Security Group。\n 提供安全组的名称和描述。在本主题中，使用名称 WebServerSG 作为示例。从 VPC 菜单中选择您 VPC 的 ID，然后选择 Yes, Create。\n 选择您刚刚创建的 WebServerSG 安全组。详细信息窗格内会显示此安全组的信息，以及可供您使用入站规则和出站规则的选项卡。\n 在 Inbound Rules 选项卡上，选择 Edit，然后执行以下操作：\n 从 Type (类型) 列表中选择 HTTP，然后在 0.0.0.0/0Source (源) 字段中输入 。 选择 Add another rule，从 Type 列表中选择 HTTPS，然后在 Source 字段中输入 0.0.0.0/0。\n 选择 Add another rule，然后从 Type 列表中选择 SSH (对于 Linux) 或 RDP (对于 Windows)。在 Source (源) 字段中输入您网络的公有 IP 地址范围。(如果不知道此地址范围，则可使用 0.0.0.0/0 作测试用途；在生产环境下，您将仅授权特定 IP 地址或地址范围访问您的实例。) 选择 Add another rule，然后从 Type 列表中选择 ALL traffic。在 Source 字段中，输入 WebServerSG 安全组的 ID。  选择 Save\n  Internet Gateway 创建 Internet 网关并将其附加到 VPC 1. 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。 2. 在导航窗格中，选择 Internet Gateways (Internet 网关)，然后选择 Create internet gateway (创建 Internet 网关)。 3. 选择刚刚创建的 Internet 网关，然后选择 Actions, Attach to VPC 4. 从列表中选择 VPC，然后选择 Attach (附加)。 路由表 将Internet Gateway Attach到VPC上，路由表配置0.0.0.0/0指向Internet Gateway，并关联子网。 之后的EC2宿主机集群，负载均衡器等都使用在这个网络里。\n负载均衡器  创建ALB应用负载均衡器，监听80端口  选择对应的子网 新建安全组，端口80， 新建目标组 注册目标此时不选择，ECS创建服务时会注册集群和对应端口进来。 下一步审核后创建。\nECS ECS宿主机集群 在ECS的界面下，创建集群\n  实例配置保持默认或根据情况自行选择。 联网配置，选择创建好的VPC，子网，创建Role允许宿主机上的ECS代理调用ECS服务的API。 创建后画面下面会显示集群信息 集群一览会显示 修改ECS宿主机集群的安全组，inbound源设置为建好的应用负载均衡器的安全组ID ECR镜像仓库 创建一个用于Build阶段上传存放软件工程Docker镜像的镜像仓库 ECS界面下，创建存储库，创建好后如下 S3桶创建 创建一个S3桶用来存放Deploy阶段CloudFormation使用的脚本模版，创建桶时选择和以上服务同一Region，并且打开桶的版本控制。 将CloudFormation模版压缩zip后上传到桶中。 将模版文件service.yaml放在templates文件夹后压缩为templates.zip。 url\nPipeline的搭建 分为Source，Build以及Deploy三阶段： 1. Source阶段设置CodeCommit上的软件工程位置，并设置Deploy阶段会使用的CloudFormation脚本模版来更新ECS服务， 2. Build阶段使用AWS CodeBuild来打包软件工程为jar包并上传至S3 3. Build阶段使用AWS CodeBuild来下载最新的jar包并打包成Docker镜像并上传到ECR， 4. Deploy阶段使用Source阶段引入的CloudFormation脚本，找到对应的宿主机集群，负载均衡器，以及上传到ECR的Docker镜像等对象，更新服务。 5. AWS CodePipeline创建后的展示图是这样的，串起了整个CICD流程 在AWS CodePipeline界面点击创建管道Pipeline，可以看到画面左侧一个基本流程，从源，到build阶段生成jar，到build阶段生成docker到部署Deploy。实际应用中用户可以随实际需要，或随着CICD流程的由简入繁在创建后编辑加入新的阶段或操作。 点击下一步。 Source阶段配置 源提供商下拉菜单选择CodeCommit，选择存储库名称和分支名称，来允许AWS CodePipeline从CodeCommit上获取软件工程源内容， 点击下一步\n此次实例使用的Demo软件工程可以从以下链接Fork： https://github.com/.....\nBuild阶段配置 AWS CodePipeline在Build阶段支持包括AWS CodeBuild，Jenkins在内的引擎，此方案选用AWS 托管的CodeBuild服务 选择新建构建项目 选择AWS CodeBuild托管的镜像，支持Ubuntu系统，运行时支持包括Java，Python，Go语言，Node.js，Docker在内的众多选择，此次方案使用Java。 构建规范这里选择使用buildspec.yml，里面预定了AWS CodeBuild在Build生命周期中要执行的动作，如 Buildspec.yml放在GitHub软件工程源代码目录中\n选择Role 新建一个Role，这个Role允许AWS CodeBuild来调用相关的AWS服务，此方案中需要调用包括S3，ECR，CloudWatch在内的服务。 * 默认创建的Role不具备对ECR的权限，需要在保存构建项目后，到IAM找到新创建的Role，编辑添加对ECR的权限否则后面Pipeline执行到Build时会报错。 保存构建项目。 打开codebuild编辑已有项目 选择构建放置的位置 类型选择S3 填入相应的存储桶名称 点击下一步。\nDeploy AWS CodePipeline部署阶段支持包括AWS CloudFormation，AWS CodeDeploy，AWS Elastic Beanstalk在内的服务提供商，此方案选用AWS CloudFormation来部署ECS容器服务。 这里暂时选择无部署，等Pipeline创建好后，编辑引入Deploy的CloudFormation模版源，再进行配置。 点击下一步。\n角色 配置AWS CodePipeline对AWS服务的调用权限，包括S3，AWS CodeBuild，AWS CloudFormation，IAM等。点击创建角色到IAM界面选择相对应的策略创建。 创建好后画面回到Pipeline，IAM创建好的Role已经显示在里面。 点击下一步。\n审核后创建管道 管道创建好后会自动运行，现有的从GitHub软件工程源代码抓取工程，打包Docker镜像并推送到ECR上。\n添加Deploy阶段CloudFormation需要的模版源 点击编辑，点击Source阶段右上角的画笔图标 可以看到AWS CodePipeline的编辑界面在南北纵向和东西横向都可以添加 在GitHub这个Source右侧，点击添加操作，选择源，操作名称Template，选择S3，输入创建好的S3桶的地址 画面往下拉，注意在输出项目这里，输入Template。 Pipeline中各阶段的传递需要制定南北向的输入输出，即Source阶段S3源的输出Template，在Deploy阶段用输入Template来衔接。 点击更新。\nBuild的构建dockers 点击Build阶段下面的添加阶段，画面右侧选择构建 选择新建构建项目 选择AWS CodeBuild托管的镜像，支持Ubuntu系统，运行时支持包括Java，Python，Go语言，Node.js，Docker在内的众多选择，此次方案使用Docker。 构建规范这里选择使用构建命令，里面预定了AWS CodeBuild在Build生命周期中要执行的动作，如 复制粘贴命令到构建命令中并修改相应参数\nversion: 0.2 phases: pre_build: commands: - $(aws ecr get-login --no-include-email) - TAG=\u0026quot;$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | head -c 8)\u0026quot; - aws s3 cp s3地址 ./ build: commands: - docker build -t 替换创建好的ECR镜像仓库的URI:${TAG} . post_build: commands: - docker push \u0026quot;替换创建好的ECR镜像仓库的URI:${TAG}\u0026quot; - printf '{\u0026quot;tag\u0026quot;:\u0026quot;%s\u0026quot;}' $TAG \u0026gt; build.json artifacts: files: build.json  选择Role 新建一个Role，这个Role允许AWS CodeBuild来调用相关的AWS服务，此方案中需要调用包括S3，ECR，CloudWatch在内的服务。 *默认创建的Role不具备对ECR的权限，需要在保存构建项目后，到IAM找到新创建的Role，编辑添加对ECR的权限否则后面Pipeline执行到Build时会报错。 保存构建项目。 点击下一步。\nCloudformation 点击Build阶段下面的添加阶段，画面右侧选择部署，选择AWS CloudFormation 操作模式选择创建或更新堆栈，输入创建的堆栈名称，模版这里输入Template::templates/service.yaml，也就是对应的输入是S3源桶中templates.zip里的service.yaml文件。功能选择CAPABILITY_NAMED_IAM。 同样需要创建一个Role，允许AWS CloudFormation调用包括IAM，ECS，ECR在内的AWS服务。 在IAM界面创建好后选择Role。 高级这里点开 在参数覆盖这里输入CloudFormation需要传入的参数，其中的固定参数也可以在S3的service.yaml中直接定义。\n{ \u0026quot;Tag\u0026quot; : { \u0026quot;Fn::GetParam\u0026quot; : [ \u0026quot;MyAppBuild\u0026quot;, \u0026quot;build.json\u0026quot;, \u0026quot;tag\u0026quot; ] }, \u0026quot;DesiredCount\u0026quot;: \u0026quot;2\u0026quot;, \u0026quot;Cluster\u0026quot;: \u0026quot;XXXXXXX\u0026quot;, \u0026quot;TargetGroup\u0026quot;: \u0026quot;XXXXX\u0026quot;, \u0026quot;Repository\u0026quot;: \u0026quot;XXXXX\u0026quot; }   Tag是Build阶段传出的Docker镜像Tag使用的值，传入CloudFormation中用于建立Task Definition的Container时从ECR拉取对应版本的Docker镜像。 DesiredCount，即想要在ECS的Service中建立的Task的数量。 Cluster，即建立好的宿主机集群的名称。 TargetGroup，即建立好的宿主机集群的应用负载均衡器的目标组的ARN。 Repository，即建立好的ECR的镜像仓库名称。  输入项目这里输入Build阶段和S3模版源的输出。 点击添加操作。 保存管道更改。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/cicd/cicd_jar_jenkins/",
	"title": "基于jenkins的java应用程序CICD解决方案",
	"tags": [],
	"description": "",
	"content": " 概述 本文概述了用jenkins完成java项目的CICD流程的所需步骤，其中涉及到codeBuild和codeDeploy的相关配置在 cicd jar codepipe中详细说明\n步骤  创建jenkins服务器 创建jenkins项目 配置source 配置codeBuild 配置codeDeploy  创建jenkins  创建Amazon EC2实例，选择实例类型和添加存储。  在“高级详细信息”里面输入启动脚本 #!/bin/bash yum -y update yum install -y ruby yum install -y aws-cli yum install –y git cd /home/ec2-user wget https://bucket-name.s3.amazonaws.com/latest/install chmod +x ./install ./install auto  bucket name对应列表为  EC2启动成功后，使用SSH到该EC2，使用如下命令检验Agent是否工作正常。\nsudo service codedeploy-agent status Result: The AWS CodeDeploy agent is running as PID 3523    ### 使用Github托管源代码，并配置webhook自动触发 首先进入自己的Github地址，点击https://github.com/settings/tokens，生成GitHub token，这个token用于jenkins访问GitHub。\n 为需要做CI/CD的GitHub创建hook，实现代码更新自动通知Jenkins，Payload URL设置Jenkins Server的地址，默认Jenkins监听8080端口。记录下生成的token字符串，比如： bf6adc27311a39ad0b5c9a63xxxxxxxxxxxxxx\n 创建一个新的repository  创建本次环境所需要的Git仓库，比如名为AWS-BJS-CodeDeploy-CICD-Jenkins。点击“Settings”配置webhooks。  点击“Add Webhooks”\n 在Payload URL，输入http://EC2公网IP地址/github-wekhook/，如下图所示： 部署Jenkins，并安装CodeDeploy插件 安装如何脚本安装Jenkins，默认Java的环境是1.7的，可以先升级到Java 1.8版本。\nsudo -s java –version yum install java-1.8.0 yum remove java-1.7.0-openjdk wget -O /etc/yum.repos.d/jenkins.repo http://jenkins-ci.org/redhat/jenkins.repo rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key yum install jenkins chkconfig jenkins on service jenkins start //查看Jenkins默认密码 cat /var/lib/jenkins/secrets/initialAdminPassword    在浏览器输入输入EC2的公网IP地址（最好绑定一个弹性EIP），比如54.223.215.xx:8080，然后出现如下界面，输入上面得到的默认密码。  创建用户名和密码，就到如下界面，这个时候Jenkins就可以进行配置了。  进入系统配置  输入Jenkins URL，点击“Add”添加Jenkins  输入Github获取的Access Token，点击“添加”。  点击“Test Connection”，没有报错说明配置成功。  添加管理插件  添加AWS CodeDeploy的插件，点击“Install without restart”  新建一Jenkins个项目，点击“Create a new project”  配置Github项目的地址，源代码管理选择Git方式。  触发构建，选择Github hook trigger for GITScm polling\n 选择“添加构建步骤”\n选择“AWS cloud build”插件\n 其余保持空白\n点击“添加构建步骤”\n选择执行 shell\naws s3 cp s3://yuan0928/target/test_springboot.jar ./ //您在codeBuild中写的文件输出的位置 mkdir target mv test_springboot.jar target/   这三行脚本的意思是把上一步骤生成的jar包添加到环境中，方便后续的部署工作。\n 选择“Post-build Actions”，输入CodeDeploy相关信息，区域选择您所在的code deploy的region 认证方式可以输入AWS Access Key和Security Key，如果是生产环境建议使用临时的credentials。  点击“应用” “保存”  "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/cicd/cicd_docker_blue_jenkins/",
	"title": "基于jenkins的容器蓝绿部署解决方案",
	"tags": [],
	"description": "",
	"content": " 概述： 本文讲述的是用jenkins做容器蓝绿部署所需相关配置， 其中涉及到的codeBuild相关的配置同文章： cicd docker bule codePipe\n步骤：  创建jenkins项目 定义源码地址和代码更新触发 增加构建步骤： 源码-\u0026gt;jar包 增加构建步骤： jar包-\u0026gt; docker镜像 增加构建后操作： 切换生产端口\n1. 创建自由风格的项目 2. 输入github项目的地址 3. 输入github项目的git地址和分支 4. 勾选Github hook trigger for GITScm polling 实现github代码更新的自动触发 5. 点击“添加构建步骤” 选择“AWS cloud build”插件 6. 输入aws的accessId 和accessKey 7. 输入code build项目的项目名称和可用区 8. 点击“添加构建步骤” 选择“AWS cloud build”插件 9. 输入aws的accessId 和accessKey 10. 输入code build项目的项目名称和可用区 11. 此项目目的为把源码打包为jar包并上传到S3桶中 12. 选择“添加构建步骤“ 13. 选择“执行 shell“   本段代码的逻辑是： 1. 根据build_number也就是每次build的环境变量值，我们判断使用哪个任务定义模板 区别在于不同的模板中容器与实例的端口号对应不同 2. 根据新的参数创建新的任务定义， 3. 更新服务中运行的任务为新任务\n14. 点击“添加构建后操作” 15.选择 lambda invocation  填写acces Id和access Key 填写lambda所在的可用区和即将调用的lambda名称   Lambda逻辑为：\n Elb接了三个监听器 80 8080 1234 分别对应两个目标组 tg1 tg2 目标组有一个tag: isProduction:Boolean 代表此目标组目前是不是生产环境所用目标组 我们将更新过的非生产环境的目标组 作为80端口的监听目标组 进行服务更新 并且更新目标组的tag  Lambda代码为： https://s3-us-west-2.amazonaws.com/westcode/blue_lambda.py\n16. 点击“应用“”保存“ 17. 点击“立即构建“ "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/cicd/automatic-apply-resource/",
	"title": "自动化脚本：监测 &amp; 自动启动可用资源",
	"tags": [],
	"description": "",
	"content": " 场景概览 某些时候某可用区的资源暂时不足，启动时会启动失败。如果客户有一些资源要求一定要在特定可用区部署特定机型，需要经常去刷新资源。\n此脚本通过持续申请资源并且一旦有空闲资源，以预留容量的方式锁定资源来解决上述问题。\n示例代码演示了在宁夏cn-northwest-1a可用区申请r5.2xlarge资源。如果失败会持续执行，如果成功自动按预留容量启动。\n点击此链接了解预留容量：https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html\n前提条件 1. 安装以及配置AWSCLI 安装：https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/cli-chap-install.html\n配置：https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/cli-chap-configure.html\naws configure  2. 安装AWS官方python SDK BOTO3 sudo easy_install pip pip install boto3  3. 执行前需要修改参数：实例类型（如c5.2xlarge），平台/操作系统(如Linux, windows，可添加多个), 可用区。 具体参数说明：https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#EC2.Client.create_capacity_reservation\n具体实现 注：以下基于python2.7\n from botocore.exceptions import ClientError import boto3 import json client = boto3.client('ec2',region_name='cn-northwest-1') while 1: print('enter the loop') try: #revise your own instance type \u0026amp; operating system \u0026amp; availability zone here!! response = client.create_capacity_reservation(InstanceType='r5.2xlarge',InstancePlatform='Linux/UNIX',AvailabilityZone='cn-northwest-1a',InstanceCount=1,EndDateType='unlimited') print('[Success]check the detailed info below or in the console') print(response) break except ClientError as e: #print(e) #Launch failed. Reason: Exceed limit if 'InstanceLimitExceeded' in str(e): print('[Failed] Reached instance Limit. Please submit request for higher limits') break #Launch failed. Reason: No resource available. elif 'Insufficient capacity' in str(e): print('[Failed] Insufficient capacity right now, making an another request...') continue #Other errors. else: print(e) break  运行此上脚本分三种情况：\n1. 执行成功，会成功预留此容量，程序运行结束。 *注意：在不使用的情况下未取消预留容量也会持续扣费。如不再使用，可随时通过控制台或SDK取消。\n #How to cancel reservation capacity? Via console or below API response = client.cancel_capacity_reservation( CapacityReservationId='xxxxxxxxxxx' )  2. 启动失败：当前无可用资源 Insufficient capacity 此可用区当前无可用资源。此时程序不会退出，会一直维持while循环，直到成功或者手动停止此程序。\n3. 启动失败：已达到实例上限 InstanceLimitExceeded 每个账户下会有instance limit, 如果已经达到此上限，无法启动成功，此时需要提case给后台申请提高此限制。\n此时程序直接退出。\n参考链接 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#EC2.Client.create_capacity_reservation\nhttps://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/network/bypassicp/",
	"title": "# 在中国合法部署海外IP",
	"tags": [],
	"description": "",
	"content": " 本文将介绍在不将主域名做 ICP 备案的情况下，在 AWS China Region 部署您的服务。若您希望：\n 在国内备案对应 .cn 域名，访问主域名 www.example.com 时自动跳转至 www.example.cn。 在国内备案对应 .cn 域名，访问主域名 www.example.com 时使用海外 CDN 节点加速。 不在国内备案 .cn 域名，使用 www.example.com 访问，且服务全部部署在海外。  可参考我们为您提供的三种部署方案：\n 利用部署在海外的 API Gateway 和 Lambda，访问 www.example.com 时返回 301 www.example.cn。 使用 CNC (网宿)的香港、台湾等节点做 CDN 回源 China Region, 经实测延迟大约为700ms, 网宿的 SLA 为2秒，丢包情况很少发生。 使用 CNC 的香港，台湾节点加速；使用电信的 CN2IP 加速访问。  一、 国内备案.cn等域名 该方案使用 Amazon API Gateway 及 Lambda 服务。您可在国内地区部署服务并注册 www.example.cn 域名并备案，当用户访问 www.example.com 时，主域名配置的海外 API Gateway 会为客户自动转调到 www.example.cn。\n架构搭建：\n 用户在中国注册代理域名，在 ICP 备案。 在 China Region 搭建代理服务器及 API Gateway。 在 Amazon Global Region 部署 Route53 + API Gateway + Lambda，可转跳服务到 China Region。  数据流：\n 用户访问主域名。 Route53 使用 geolocation route policy 功能，根据用户所处地区向不同 API Gateway 发送请求。  海外用户请求将被导航到 API 2。 国内用户请求将被导航到 API 1，调用相关 Lambda 方法。  Lambda 将用户重新导航到您在国内注册的域名中。 您在国内的域名将被解析至中国的 API Gateway API DNS 名称。 用户使用手机客户端直接访问位于中国的 API Gateway。  二、 CNC（网宿） 回源 China Region 该方案使用 CDN 加速，您需在国内部署网络服务，当国内用户访问主域名时，可使用位于香港的 CNC 回源位于国内的服务。\n架构搭建：\n 用户在中国注册代理域名，在 ICP 备案。 在 China Region 搭建代理服务器及 API Gateway。 注册位于海外（香港、台湾等）的CDN节点。 在 Global Region 部署 Route 53 + API Gateway，可转跳服务到 CDN 节点。  数据流：\n 客户访问主域名。 Route 53 使用 geolocation route policy 功能，根据用户所处地区为用户分配 IP。  海外用户请求将被导航到海外 API Gateway。 国内用户请求将被导航至位于香港或台湾的 CDN 节点  CDN 节点回源位于国内的代理服务。 您在国内的域名将被解析至中国的 API Gateway API DNS 名称。 用户使用手机客户端直接访问位于中国的 API Gateway。  三、 海外CNC节点加速 该方案使用海外 CNC 节点加速，当用户访问主域名时，可使用位于海外的 CDN 节点加速访问，您也可选择 CN2 链路优化访问速度，该方案不需要在国内部署代理服务。\n架构搭建：\n 注册位于海外（香港、台湾等）的CDN节点。 在 Global Region 部署 Route 53 + API Gateway，可转跳服务到 CDN 节点。  数据流：\n 客户访问主域名。 Route 53 使用 geolocation route policy 功能，根据用户所处地区为用户分配 IP。  海外用户请求将被导航到海外 API Gateway。 国内用户请求将被导航至位于香港或台湾的 CDN 节点  CDN 节点回源到海外资源，并返回给用户。  "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/network/",
	"title": "Network",
	"tags": [],
	"description": "",
	"content": " VPC 配置指南 海外域名部署方案：海外域名向国内用户提供服务 快速自建VPN "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/network/vpc_guide/",
	"title": "VPC配置指南",
	"tags": [],
	"description": "",
	"content": " 本文主要包含以下内容\n 公有子网（public subnet ）和 私有子网（private subnet ）的区别 如何新建 IGW, 如何更改路由表 如何创建 NAT 网关,如何更改路由表 合理的 web hosting 的网络拓扑 VPC Wizard  公有子网与私有子网  子网: VPC 是跨可用区的. 在创建 VPC 后需要为每个可用区添加一个或多个子网. 子网不可跨可用区. 公有子网( public subnet ): 子网的关联路由表 包含 指向 Internet 网关(Internet Gateways)的路由的子网 私有子网( private subnet): 子网的关联路由表 不包含 指向 Internet 网关(Internet Gateways)的路由的子网  仅限 VPN 的子网: 特别的,一个子网没有通向 Internet 网关(Internet Gateways)的路由, 但其流量会被路由到虚拟专用网关以进行 VPN 连接, 则这个子网就是仅限 VPN 的子网   如上图,\n Subnet 1: 有通向 Internet 网关的路由, 因此它是公有子网 Subnet 2: 没有通向 Internet 网关的路由, 因此它是私有子网 Subnet 3: 没有通向 Internet 网关的路由, 但流量可达 VPN , 因此它是仅限 VPN 的子网  Internet Gateways 使用 Internet 网关(Internet Gateways, igw), 可实现 VPC 中的实例与 Internet 之间的通信\nInternet 网关有两个用途:\n 在 VPC 路由表中为 Internet 可路由流量提供目标 为已经分配了公有 IPv4 地址的实例执行网络地址转换 (NAT)  当生成AWS账户的时候，AWS系统会默认的在每一个区域内都生成一个默认的VPC，并且这个默认的VPC已经绑定了一个Internet网关；一个Internet网关一次只能绑定一个VPC；当VPC中有EC2实例等AWS资源的时候，Internet网关是不能手动和相结合的VPC相分离的\n 路由表\n每个子网都会和路由表相结合使用，并且只能使用一个路由表；VPC中的子网是共有子网还是私有子网是由该子网使用的路由表决定的\n如果该路由表中有Internet网关路由条目，那么该子网就是共有子网；\n路由表由一系列的路由规则组成，决定了子网的访问权限；默认情况下，同一个VPC之间的子网之间是可以相互通信的；当路由表和子网已经结合的情况下，该路由表是不能被删除的。\n 配置 Internet 网关 Internet 网关在配置时需要具有对应的子网, 在配置之前请确保您已经添加了所需的子网, 有关子网的更多信息, 请参阅VPC 和子网\n 创建 Internet 网关并将其附加到 VPC\n 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。\n 在导航窗格中，选择 Internet Gateways (Internet 网关)，然后选择 Create internet gateway (创建 Internet 网关)。 (可选) 为 Internet 网关命名，然后选择 Create (创建)\n 选择刚刚创建的 Internet 网关，然后选择 Actions, Attach to VPC (操作，附加到 VPC)。 从列表中选择 VPC，然后选择 Attach (附加)。\n   创建自定义路由表\n 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。\n 在导航窗格中，选择 Route Tables，然后选择 Create Route Table。 在 Create Route Table 对话框中，可以选择命名您的路由表，选择您的 VPC，然后选择 Yes, Create。\n   选择您刚刚创建的自定义路由表。详细信息窗格中会显示选项卡，以供您使用其路径、关联和路线传播。\n 在 Routes 选项卡中，依次选择 Edit、Add another route，然后根据需要添加以下路由。完成此操作后，选择 Save。\n 对于 IPv4 流量，在 Destination (目的地) 框中指定 0.0.0.0/0，然后在 Target (目标) 列表中选择 Internet 网关 ID。\n 对于 IPv6 流量，在 Destination (目的地) 框中指定 ::/0，然后在 Target (目标) 列表中选择 Internet 网关 ID。\n   关于这一步路由表配置的解释\n该路由表所属的VPC 的CIDR是192.168.0.0/16, 现该路由表有两个条目\n local 网关路由条目(第一行): 默认生成, 手动不能更改  子网可以通过 local 网关路由条目和该 VPC (192.168.0.0./16)中的其他子网互相通信\n本条目是 VPC 间互相通信的保证, 无法修改\n Internet 网关路由条目(第二行)  通过 Internet 网关路由条目, 子网可以通过其对应的Internet 网关和外部网络(0.0.0.0/0)通信\n此时，这个子网由于有Internet网关路由条目就叫做共有子网, 如果这个子网的路由表中没有通过igw-xxxxxx这个Internet网关所对应的路由条目的话, 这个子网就不能访问外网, 就叫做私有子网\n  在 Subnet Associations 选项卡上，选择 Edit，选中子网的 Associate 复选框，然后选择 Save。    有关路由表的更多信息，请参见路由表。\nNAT 网关 使用网络地址转换 (NAT) 网关允许私有子网中的实例连接到 Internet 或其他 AWS 服务，但阻止 Internet 发起与这些实例的连接\n要创建 NAT 网关，您必须指定 NAT 网关应处于哪个公有子网中。有关公有子网和私有子网的更多信息，请参阅子网路由。还必须在创建 NAT 网关时指定与该网关关联的弹性 IP 地址。创建 NAT 网关之后，必须更新与您的一个或多个私有子网关联的路由表，以将 Internet 绑定流量指向该 NAT 网关。这使您的私有子网中的实例可以与 Internet 通信。\n配置 NAT 网关  创建 NAT 网关\n 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/。\n 在导航窗格中，依次选择 NAT Gateways、Create NAT Gateway。\n   指定要在其中创建 NAT 网关的子网，并选择要与该 NAT 网关关联的弹性 IP 地址的分配 ID。完成后，选择 Create a NAT Gateway。   注意\nNAT 网关所处的子网必须为公有子网\n  NAT 网关会显示在控制台中。片刻之后，其状态会更改为 Available，此后它即准备好供您使用。    如果 NAT 网关变为 Failed 状态，则表示在创建过程中发生了错误。有关更多信息，请参阅 NAT 网关变为 Failed 状态。\n 为 NAT 网关配置路由表\n 打开 Amazon VPC 控制台 https://console.aws.amazon.com/vpc/\n 在导航窗格中，选择 Route Tables。\n 选择与私有子网关联的路由表，然后依次选择 Routes、Edit。\n 选择 Add another route。对于 Destination，键入 0.0.0.0/0。对于 Target，选择 NAT 网关的 ID。\n   在 Subnet Associations 选项卡上，选择 Edit，选中子网的 Associate 复选框，然后选择 Save   选择 Save。   为确保 NAT 网关可以访问 Internet，与 NAT 网关所在子网关联的路由表必须包含使 Internet 流量指向 Internet 网关的路由。有关更多信息，请参阅 创建自定义路由表。如果删除 NAT 网关，则 NAT 网关路由会保留为 blackhole 状态，直到您删除或更新这些路由。有关更多信息，请参阅 在路由表中添加和删除路由。\n合理的 web hosting 的网络拓扑 一个合理的 Web Hosting 应该包含有以下几部分:\n Internets Gateway\n Elastic Load Balancing（ELB）\n  Elastic Load Balancing 可以在多个目标（如 Amazon EC2 实例、容器和 IP 地址）之间自动分配传入的应用程序流量，实现负载均衡。它可以在单个可用区内处理不断变化的应用程序流量负载，也可以跨多个可用区处理此类负载。Elastic Load Balancing 提供三种负载均衡器，它们均能实现高可用性、自动扩展和可靠的安全性，因此能让您的应用程序获得容错能力，有关 ELB 的更多信息，请参阅Elastic Load Balancing。\n一个合理的 ELB：\n 直接与 Internets Gateway 连接 与 Auto Scaling Group 连接\n 堡垒机(可用 NAT 实例代替) / NAT 网关\n  通常情况下，堡垒机（也称为“跳转机”）是在系统中访问私有主机的一个最佳实践。例如，您的系统可能包含一个不希望被公开访问的应用服务器，当需要在这台服务器上进行产品的更新或系统补丁程序的管理时，您通常会登录到堡垒机，然后从那里访问（即“跳转到”）应用服务器。\n在本拓扑中，Web 实例以及数据库实例位于私有子网中，无法被直接访问。因此，您需要通过堡垒机来访问并管理这些实例。\n一个合理的堡垒机：\n 最好仅向特定的IP地址范围开放，这个地址范围通常可设定为您单位的企业网络 直接与 Internets Gateway 连接 位与公有子网\n 位与 Auto Scaling Group 中的 Web 实例（也可以是其他类型的应用实例）\n  使用 Amazon EC2 Auto Scaling，您可以维持应用程序的可用性，并根据自己定义的条件以动态方式自动扩展或缩减 Amazon EC2 的容量。您可以将 Amazon EC2 Auto Scaling 用于 EC2 实例的队列管理，以帮助维持队列的正常运行和可用性，并确保当前运行的是所需数量的 Amazon EC2 实例。您还能将 Amazon EC2 Auto Scaling 用于 EC2 实例的动态扩展，以便在需求高峰期自动增加 Amazon EC2 实例的数量来维持性能，并在需求较低时自动减少容量来降低成本。\n通常情况下，Auto Scaling 会与 ELB 结合使用，之后实例在启动后会自动加入 ELB 的目标组，在终止实例前会先等待 ELB 连接耗尽。有关 Auto Scaling 的更多信息，请参阅Auto Scaling。\n 为了保证实例的安全与可用性，实例应分别位于多个可用区的私有子网中\n 数据库实例\n 为了保证您数据的安全，数据库实例不应能直接从外网访问，数据库实例应位于私有子网中。\n 使用主从架构：\n 将读操作和写操作分离到不同的数据库上，避免主服务器出现性能瓶颈\n 主服务器进行写操作时，不影响查询应用服务器的查询性能，降低阻塞，提高并发\n 数据拥有多个容灾副本，提高数据安全性，同时当主服务器故障时，可立即切换到其他服务器，提高系统可用性\n  如图所示，图中橙色实线为正常状况下流经数据库的流量，当主服务器发生故障后，从服务器可代替主服务器提供服务，此时的流量如橙色虚线所示。\n 为了保证可用性，主数据库与从数据库应位与不同的可用区中   VPC Wizard VPC 控制台中提供了四种 VPC 向导用于创建常用场景下的 VPC 的创建\n 带单个公有子网的 VPC:  适用于运行单层、面向公众的 Web 应用程序 (如博客或简单网站) 的 VPC。\n 带有公有子网和私有子网( NAT)的 VPC:  适用于运行面向公众的 Web 应用程序的 VPC，同时仍在第二个子网中保留非公开访问的后端服务器。\n 具有公有和私有子网以及 AWS 托管 VPN 访问的 VPC:  适用于将数据中心扩展到云中的 VPC，并实现从 VPC 直接访问 Internet。\n 仅具有私有子网, 以及 AWS 托管 VPN 访问权限的 VPC:  适用于将数据中心扩展到云中的 VPC，无需将您的网络连接到 Internet 即可使用 Amazon 基础设备。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/database/redis_benchmark/",
	"title": "Amazon ElastiCache for Redis 基准测试",
	"tags": [],
	"description": "",
	"content": " 本文主要目的是为 ElasticCache 下的 Redis 提供测试指南.\n完成测试的时间大约为10分钟\n 重要\n本测试默认您已经拥有了 AWS 账户并创建了 IAM 用户\n若未执行以上设置，可参考这里\n 配置安全组 新建 VPC 安全组，具体步骤参考适用于 Amazon VPC 的 IPv4 入门\n将安全组的入站规则设置为\n Type: ALL Traffice Protocol: ALL Port Range: ALL Source: 选择 Custom IP，然后键入 0.0.0.0/0。   重要\n除演示之外，建议不要使用 0.0.0.0/0，因为它允许从 Internet 上的任何计算机进行访问。在实际环境中，您需要根据自己的网络设置创建入站规则。\n 准备 Redis  登录 AWS 管理控制台并通过以下网址打开 Amazon ElastiCache 控制台：https://console.amazonaws.cn/elasticache/。\n 选择控制面板中的 Redis, 在点击创建。\n   在创建您的 Amazon ElasticCache 集群界面, 按照以下内容填写:\n 集群引擎: Redis Redis 设置  名称: benchmark-redis 节点类型: cache.r4.4xlarge 副本数量: 无  高级 Redis 设置  子网组: 创建新的 名称: benchmark-redis-subent VPC ID: 选择一个具有公有子网的VPC(建议使用默认 VPC), 点击这里查看关于 VPC 的设置指南 子网: 选择一个公有子网 首选可用区: 无首选项  安全性  安全组: 选择您在配置安全组这一步骤中新建的安全组  备份  启动自动备份: 不勾选  其他: 全部保持默认    选择 创建 以启动集群。  准备 EC2  启动实例\n 打开 Amazon EC2 控制台 https://console.aws.amazon.com/ec2/。 从控制台控制面板中，选择 启动实例。 Choose an Amazon Machine Image (AMI) 页面显示一组称为 Amazon 系统映像 (AMI) 的基本配置，作为您的实例的模板。选择 Amazon Linux AMI 2 的 HVM 版本 AMI。 在选择实例类型 页面上，您可以选择实例的硬件配置。选择 m4.4xlarge 类型 在配置实例详细信息页面上，自动分配公有 IP 选择启用，其他选择默认 在配置安全组页面选择选择一个现有的安全组，并在表格中选择配置 VPC这一步骤中创建的安全组 在审核页面选择启动    当系统提示提供密钥时，选择 选择现有的密钥对，然后选择合适的密钥对。若没有创建密钥对，请参考创建密钥对\n准备好后，选中确认复选框，然后选择 启动实例。\n   连接到 EC2  请参考使用 SSH 连接到 Linux 实例\n 下载和安装 GNU Compiler Collection (gcc)  在连接到 EC2 实例后，在 EC2 实例的命令提示符中键入下面的命令，然后在确认提示符处键入 y\nsudo yum install gcc   下载并编译 redis-cli 实用工具。此实用工具包含在 Redis 软件发布版中\nwget http://download.redis.io/redis-stable.tar.gz tar xvzf redis-stable.tar.gz cd redis-stable make   开始测试 在 EC2 实例的命令提示符处，键入以下命令，并使用您的集群的终端节点替换**中的内容\nsrc/redis-benchmark -h \u0026lt;your-redis-endpoint\u0026gt; -p 6379 -t set -r 100000 -n 1000000  测试结果类似下图\n若您需要其他情况下的性能测试, 可以参考 Redis 中国站\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/database/aurora-vs-mysql/",
	"title": "Aurora VS MySQL 压测",
	"tags": [],
	"description": "",
	"content": " 实验目的  本实验大约耗时35分钟\n 使用 sysbench 对Amazon Aurora与RDS MySQL进行基准测试, 对比二者的读写性能.\n以下是本次测试的架构\n涉及组件 - Aurora - RDS - EC2\n实验步骤 配置 VPC (可选) 新建 VPC 安全组，具体步骤参考适用于 Amazon VPC 的 IPv4 入门\n将安全组的入站规则设置为\n Type: ALL Traffice Protocol: ALL Port Range: ALL Source: 选择 Custom IP，然后键入 0.0.0.0/0。   重要\n除演示之外，建议不要使用 0.0.0.0/0，因为它允许从 Internet 上的任何计算机进行访问。在实际环境中，您需要根据自己的网络设置创建入站规则。\n 启动Aurora实例  登录 AWS 管理控制台 并通过以下网址打开 Amazon RDS 控制台：https://console.aws.amazon.com/rds/。\n 在导航窗格中，选择实例。\n 选择启动数据库实例。启动数据库实例向导在选择引擎页面打开。\n   选择 Amazon Aurora, 并将版本选择为与 MySQL 5.6 兼容，然后选择下一步。\n 在指定数据库详细信息页面上，指定数据库实例信息。选择下列值，然后选择 下一步。  数据库实例类: db.r4.xlarge 多可用区部署: 是 数据库实例标识符: 例如my-aurora 主用户名: 例如root 主密码: 用户自定义  在配置高级设置页面上，提供 RDS 启动 MySQL 数据库实例所需的其他信息。选择下列值，然后选择 下一步。\n Virtual Private Cloud (VPC)：选择您在配置 VPC这一步骤中创建的安全组所对应的 VPC 公开可用性：否 可用区: 根据您的实际区域来更改, 但请保证之后的MySQL与EC2都在这一区域中 VPC安全组：创建新的VPC安全组 数据库集群标识符: my-mysql-cluster 数据库名称：dbname 备份保留期：1 天 加密: 禁用加密 备份保留期: 1天 监控: 禁用增强监控 其他请选择默认   启动MySQL实例  登录AWS管理控制台,并通过以下网址打开Amazon RDS控制台：https://console.aws.amazon.com/rds/。\n 在导航窗格中，选择实例。\n 选择启动数据库实例。启动数据库实例向导在选择引擎页面打开。\n 选择 MySQL，然后选择下一步。\n 选择使用案例页面询问您是否计划使用所创建的数据库实例进行生产。选择 生产，然后选择 下一步 。  在指定数据库详细信息页面上，指定数据库实例信息。选择下列值，然后选择 下一步。\n 数据库引擎版本: MySQL 5.6.41 数据库实例类：db.r4.xlarge 多可用区部署：是 存储类型：预置IOPS(SSD) 分配的存储空间：100GiB 预置 IOPS: 1000 数据库实例标识符：键入 my-mysql。 主用户名：键入 root。 主密码和确认密码：用户自定义 其他设置保持默认    在配置高级设置页面上，提供 RDS 启动 MySQL 数据库实例所需的其他信息。选择下列值，然后选择 下一步。\n Virtual Private Cloud (VPC)：选择Aurora使用的安全组 公开可用性：否 可用区: 与之前 Aurora 的可用区相同 VPC安全组：选择现有 VPC 安全组，并且选择配置 VPC这一步骤中创建的安全组 数据库名称：键入dbname 备份保留期：1 天 其他请选择默认    启动Aurora Multi-AZ部署方式，可以在控制台看到2个数据库实例；启动RDS MySQL Multi-AZ部署方式，在控制台只能看到一个主实例\n启动压测机EC2  启动实例\n 打开 Amazon EC2 控制台 https://console.aws.amazon.com/ec2/。选择您要在其中创建EC2实例的区域。这里请保证与之前创建Aurora,MySQL 的区域相同。\n 从控制台控制面板中，选择 启动实例。\n Choose an Amazon Machine Image (AMI) 页面显示一组称为 Amazon 系统映像 (AMI) 的基本配置，作为您的实例的模板。选择 Amazon Linux AMI 2 的 HVM 版本 AMI。\n 在选择实例类型 页面上，您可以选择实例的硬件配置。实例的数量输入4并选择 r4.xlarge 类型\n 在配置实例详细信息页面上，自动分配公有 IP 选择启用，并保证选择子网和刚才的数据库在同一个可用区，点击下一步\n    在添加存储页面上, 点击下一步\n 在添加标签页面上，点击下一步\n 在配置安全组页面选择选择一个现有的安全组，或者创建一个新的安全组，\n 在审核页面选择启动\n 当系统提示提供密钥时，选择 选择现有的密钥对，然后选择合适的密钥对。若没有创建密钥对，请参考创建密钥对\n准备好后，选中确认复选框，然后选择 启动实例。\n  安装Sysbench 请参考使用 SSH 连接到 Linux 实例\n在连接到 EC2 实例后，依次输入以下命令，在实例中安装sysbench, 您需要在4台EC2上分别执行如下命令\n下载sysbench\nsudo yum -y install bzr automake libtool mysql mysql-devel bzr branch lp:sysbench  编译和安装sysbench\ncd sysbench ./autogen.sh ./configure make cd sysbench  进行Sysbench测试  准备数据  只需要在一台EC2上执行以下命令，为sysbench测试准备数据；您在为MySQL准备数据的同时，可以在另外一台机器上为Aurora准备数据。\n请根据您的实际情况替换下面命令中的mysql-host, mysql-user, mysql-password,mysql-db参数\n./sysbench --test=tests/db/oltp.lua --mysql-host=\u0026lt;rds-mysql-instancehost-name\u0026gt; \\ --mysql-port=3306 --mysql-user=\u0026lt;db-username\u0026gt; --mysql-password=\u0026lt;db-password\u0026gt; \\ --mysql-db=\u0026lt;db-name\u0026gt; --mysql-table-engine=innodb --oltp-table-size=25000 \\ --oltp-tables-count=250 --db-driver=mysql prepare   执行read heavy测试   请在4台EC2上同时执行以下命令\n ./sysbench --test=tests/db/oltp.lua --mysql-host=\u0026lt;rds-aurora-instancehost-name\u0026gt; \\ --oltp-tables-count=250 --mysql-user=\u0026lt;db-username\u0026gt; --mysql-password=\u0026lt;db-password\u0026gt; \\ --mysql-port=3306 --db-driver=mysql --oltp-tablesize=25000 \\ --mysql-db=\u0026lt;db-name\u0026gt; --max-requests=0 --oltp_simple_ranges=0 --oltp-distinct-ranges=0 \\ --oltp-sum-ranges=0 --oltp-order-ranges=0 --max-time=300 \\ --oltp-read-only=on --num-threads=300 run  以下是MySQL测试结果，我们需要将以下4台主机的测试结果相加才是我们的最终结果\n以下是Aurora的测试结果\n 执行write heavy测试   请在4台EC2上同时执行以下命令\n ./sysbench --test=tests/db/oltp.lua --mysql-host=\u0026lt;rds-aurora-instancehost-name\u0026gt; \\ --oltp-tables-count=250 --mysql-user=\u0026lt;db-username\u0026gt; --mysql-password=\u0026lt;db-password\u0026gt; \\ --mysql-port=3306 --db-driver=mysql --oltp-tablesize=25000 \\ --mysql-db=\u0026lt;db-name\u0026gt; --max-requests=0 --max-time=300 --oltp_simple_ranges=0 \\ --oltp-distinct-ranges=0 --oltp-sum-ranges=0 --oltporder-ranges=0 \\ --oltp-point-selects=0 --num-threads=450 --randtype=uniform run  以下是MySQL的测试结果\n以下是Aurora测试结果\n由于机型的差异，选择更大的机型，Aurora与MySQL的性能差异表现得更加明显。\n更多阅读 Amazon Aurora Performance Assessment\n知己知彼-对Aurora进行压力测试\nAmazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/database/",
	"title": "Database",
	"tags": [],
	"description": "",
	"content": " RedShift vs. MySQL对比实验 Aurora vs. MySQL性能对比试验 MongoDB自动部署 ElastiCache:Redis基准测试 DynamoDB Proxy Using API Gateway "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/database/redshift_mysql/",
	"title": "Redshift &amp; MySQL 性能对比实验",
	"tags": [],
	"description": "",
	"content": " 实验目的 提供 Redshift 和 RDS MySQL 在千万级数据中执行联表查询的性能对比。\n \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n涉及组件  EC2 RedShift RDS S3 VPC  实验步骤  重要\n本实验默认您已经拥有了 AWS 账户并创建了 IAM 用户\n若未执行以上设置，可参考这里\n 配置 VPC 新建 VPC 安全组，具体步骤参考适用于 Amazon VPC 的 IPv4 入门\n将安全组的入站规则设置为\n Type: ALL Traffice Protocol: ALL Port Range: ALL Source: 选择 Custom IP，然后键入 0.0.0.0/0。   重要\n除演示之外，建议不要使用 0.0.0.0/0，因为它允许从 Internet 上的任何计算机进行访问。在实际环境中，您需要根据自己的网络设置创建入站规则。\n 配置 RedShift  为 Amazon Redshift 创建 IAM 角色\n 登录 AWS 管理控制台 并通过以下网址打开 IAM 控制台 https://console.aws.amazon.com/iam/。 在左侧导航窗格中，选择 Roles。 选择 Create role 在 AWS Service 组中，选择 Redshift。 在 Select your use case 下，选择 Redshift - Customizable，然后选择 Next: Permissions。 在 Attach permissions policies 页面上，选择 AdministratorAccess，然后选择 Next: Review。 对于 Role name，为您的角色键入一个名称。在本教程中，请键入 myRedshiftRole。 检查信息，然后选择 Create Role。 选择新角色的角色名称。 将 Role ARN 复制到您的剪贴板 — 此值是您刚刚创建的角色的 Amazon 资源名称 (ARN)。在之后的实验中（导入数据到 RedShift），将会使用到该值。  登录 AWS 管理控制台 并通过以下网址打开 Amazon Redshift 控制台：https://console.aws.amazon.com/redshift/ 。\n 在主菜单中，选择您要在其中创建群集的区域。在本教程中，请选择 美国西部（俄勒冈）。   . 在 Amazon Redshift 仪表板上，选择 Launch Cluster。 “Amazon Redshift Dashboard”如下所示! 在“Cluster Details”页面上，输入下列值，然后选择 Continue：\n Cluster Identifier：键入 rs-vs-mysql。\n Database Name：将此框留空。Amazon Redshift 将会创建一个名为 dev 的默认数据库。\n Database Port：键入数据库将接受连接的端口号。您应该在本教程的先决条件步骤确定了端口号。在启动群集之后便无法更改端口号，因此请确保您知道防火墙中的一个开放端口号，这样才能从 SQL 客户端工具连接到群集中的数据库。\n Master User Name：键入 masteruser。在群集可供使用之后，您将使用此用户名和密码连接到您的数据库。\n Master User Password 和 Confirm Password：为主用户账户键入密码。    在“Node Configuration”页面上，选择下列值，然后选择 Continue：\n Node Type：dc1.large Cluster Type：Multi Node Number of compute nodes：2    在“Additional Configuration”页面上，\n Choose a VPC：选择您在配置 VPC这一步骤中创建的安全组所对应的 VPC Publicly Accessible：Yes VPC Security Groups：选择您在配置 VPC这一步骤中创建的安全组 AvailableRoles： 选择myRedshiftRole 其他选项采用默认选项即可   然后选择Continue。\n 在“Review”页面上，查看您进行的选择，然后选择 Launch Cluster。  配置 RDS  登录 AWS 管理控制台 并通过以下网址打开 Amazon RDS 控制台：https://console.aws.amazon.com/rds/。\n 在 Amazon RDS 控制台的右上角，选择您要在其中创建数据库实例的区域。这里为保证与之前创建 RedShift 的区域相同。\n 在导航窗格中，选择实例。\n 选择启动数据库实例。启动数据库实例向导在选择引擎页面打开。 选择 MySQL，然后选择下一步。\n 选择使用案例页面询问您是否计划使用所创建的数据库实例进行生产。选择 开发/测试，然后选择 下一步 。\n 在指定数据库详细信息页面上，指定数据库实例信息。选择下列值，然后选择 下一步。\n 数据库实例类：db.r4.xlarge 存储类型：预置 IOPS 预置 IOPS：1000 数据库实例标识符：键入 rs-vs-mysql。 主用户名：键入 masteruser。 主密码和确认密码：键入您的密码 其他设置保持默认：    在配置高级设置页面上，提供 RDS 启动 MySQL 数据库实例所需的其他信息。选择下列值，然后选择 下一步。\n Virtual Private Cloud (VPC)：选择您在配置 VPC这一步骤中创建的安全组所对应的 VPC 公开可用性：是 VPC安全组：选择现有 VPC 安全组，并且选择配置 VPC这一步骤中创建的安全组 数据库名称：键入dbname 备份保留期：1 天 其他请选择默认   配置 EC2  启动实例\n 打开 Amazon EC2 控制台 https://console.aws.amazon.com/ec2/。选择您要在其中创建EC2实例的区域。这里为保证与之前创建 RedShift、RDS 的区域相同, 请选择俄勒冈。\n 从控制台控制面板中，选择 启动实例。\n Choose an Amazon Machine Image (AMI) 页面显示一组称为 Amazon 系统映像 (AMI) 的基本配置，作为您的实例的模板。选择 Amazon Linux AMI 2 的 HVM 版本 AMI。\n 在选择实例类型 页面上，您可以选择实例的硬件配置。选择 t2.small 类型\n 在配置实例详细信息页面上，自动分配公有 IP 选择启用，其他选择默认\n 在配置安全组页面选择选择一个现有的安全组，并在表格中选择配置 VPC这一步骤中创建的安全组\n 在审核页面选择启动\n 当系统提示提供密钥时，选择 选择现有的密钥对，然后选择合适的密钥对。若没有创建密钥对，请参考创建密钥对\n  准备好后，选中确认复选框，然后选择 启动实例。\n 连接到 EC2\n  请参考使用 SSH 连接到 Linux 实例\n 在实例中安装 MySQL  在连接到 EC2 实例后，依次输入以下命令，在实例中安装 MySQL\n wget http://repo.mysql.com/mysql-community-release-el6-5.noarch.rpm sudo rpm -ivh mysql-community-release-el6-5.noarch.rpm sudo yum install mysql-community-server -y   在实例中安装 psql 工具  在连接到 EC2 实例后，输入以下命令，在实例中安装 psql\n sudo yum install postgresql-server -y  导入数据到 RDS  切换目录  输入命令\n cd ~   通过 AWS 命令行界面（CLI）下载数据  AWS CLI 已经预安装在了 Amazon Linux AMI 上，但您仍需要进行相应的配置，详情可参考配置 AWS CLI\n在 EC2 中配置完成 AWS CLI 后，输入以下命令拷贝测试数据 - Global\n aws s3 cp s3://rs-vs-rds/test_date/2006.csv 2006.csv aws s3 cp s3://rs-vs-rds/test_date/2007.csv 2007.csv aws s3 cp s3://rs-vs-rds/test_date/2008.csv 2008.csv   中国区\naws s3 cp s3://rs-vs-rds/2006.csv 2006.csv --source-region cn-northwest-1 --region \u0026lt;your region\u0026gt; aws s3 cp s3://rs-vs-rds/2006.csv 2007.csv --source-region cn-northwest-1 --region \u0026lt;your region\u0026gt; aws s3 cp s3://rs-vs-rds/2006.csv 2008.csv --source-region cn-northwest-1 --region \u0026lt;your region\u0026gt;    连接到 RDS  参考与运行 MySQL 数据库引擎的数据库实例连接\n 创建表格  输入命令\n use dbname;   CREATE TABLE demobigtable ( Year integer, Month integer, DayofMonth integer, DayOfWeek varchar(255), DepTIme varchar(255), CRSDepTime varchar(255), ArrTime varchar(255), CRSArrTime varchar(255), UniqueCarrier varchar(255), FlightNum varchar(255), TailNum varchar(255), ActualElapsedTime varchar(255), CRSElapsedTime varchar(255), AirTime varchar(255), ArrDelay varchar(255), DepDelay varchar(255), Origin varchar(255), Dest varchar(255), Distance varchar(255), TaxiIn varchar(255), TaxiOut varchar(255), Cancelled varchar(255), CancellationCode varchar(255), Diverted varchar(255), CarrierDelay varchar(255), WeatherDelay varchar(255), NASDelay varchar(255), SecurityDelay varchar(255), LateAircraftDelay varchar(255) ) ;   加载数据\n执行 SQL 语句\nload data local infile '2006.csv' into table demobigtable fields terminated by ',' lines terminated by '\\n' IGNORE 1 LINES; load data local infile '2007.csv' into table demobigtable fields terminated by ',' lines terminated by '\\n' IGNORE 1 LINES; load data local infile '2008.csv' into table demobigtable fields terminated by ',' lines terminated by '\\n' IGNORE 1 LINES;   测试 RDS 输入命令\nSELECT a.Year,a.Month,a.DayofMonth,a.FlightNum,a.TailNum FROM (SELECT Year,Month,DayofMonth,FlightNum,TailNum FROM demobigtable GROUP BY Year,Month,DayofMonth,FlightNum,TailNum) AS a LIMIT 10;  获取 RDS 实验结果\n导入数据到RedShift  输入以下命令退出 RDS，若您之前已经退出了 RDS，请忽略该步骤。\nexit；  连接到 RedShift\n  参考使用 psql 工具连接到您的群集\n 创建表格\nCREATE TABLE demobigtable ( Year integer, Month integer, DayofMonth integer, DayOfWeek varchar(255), DepTIme varchar(255), CRSDepTime varchar(255), ArrTime varchar(255), CRSArrTime varchar(255), UniqueCarrier varchar(255), FlightNum varchar(255), TailNum varchar(255), ActualElapsedTime varchar(255), CRSElapsedTime varchar(255), AirTime varchar(255), ArrDelay varchar(255), DepDelay varchar(255), Origin varchar(255), Dest varchar(255), Distance varchar(255), TaxiIn varchar(255), TaxiOut varchar(255), Cancelled varchar(255), CancellationCode varchar(255), Diverted varchar(255), CarrierDelay varchar(255), WeatherDelay varchar(255), NASDelay varchar(255), SecurityDelay varchar(255), LateAircraftDelay varchar(255) ) ;  加载数据\n  请将以下 COPY 命令中的**替换为您的角色 ARN，输入至 psql 命令行中 - Global\n copy demobigtable from 's3://rs-vs-rds/test_date/2006.csv' credentials 'aws_iam_role=\u0026lt;iam-role-arn\u0026gt;' delimiter ',' IGNOREHEADER 1 ACCEPTINVCHARS; copy demobigtable from 's3://rs-vs-rds/test_date/2007.csv' credentials 'aws_iam_role=\u0026lt;iam-role-arn\u0026gt;' delimiter ',' IGNOREHEADER 1 ACCEPTINVCHARS; copy demobigtable from 's3://rs-vs-rds/test_date/2008.csv' credentials 'aws_iam_role=\u0026lt;iam-role-arn\u0026gt;' delimiter ',' IGNOREHEADER 1 ACCEPTINVCHARS;   中国区\ncopy demobigtable from 's3://rs-vs-rds/2006.csv' credentials 'aws_iam_role=\u0026lt;iam-role-arn\u0026gt;' delimiter ',' IGNOREHEADER 1 ACCEPTINVCHARS; copy demobigtable from 's3://rs-vs-rds/2007.csv' credentials 'aws_iam_role=\u0026lt;iam-role-arn\u0026gt;' delimiter ',' IGNOREHEADER 1 ACCEPTINVCHARS; copy demobigtable from 's3://rs-vs-rds/2008.csv' credentials 'aws_iam_role=\u0026lt;iam-role-arn\u0026gt;' delimiter ',' IGNOREHEADER 1 ACCEPTINVCHARS;   测试 RedShift  开启 sql 时间记录功能\n\\timing on  执行 SQL 语句\nSELECT a.Year,a.Month,a.DayofMonth,a.FlightNum,a.TailNum FROM (SELECT Year,Month,DayofMonth,FlightNum,TailNum FROM demobigtable GROUP BY Year,Month,DayofMonth,FlightNum,TailNum) AS a LIMIT 10;   实验结果 RDS 实验结果 RedShift 实验结果 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/database/api-gateway-proxy-for-ddb/",
	"title": "利用API Gateway访问DynamoDB",
	"tags": [],
	"description": "",
	"content": " 本文介绍如何利用API Gateway作为proxy直接对dynamoDB进行访问，将示例get和post两种方法。\n通过这种方式，无需构建serverside，无需提供credentials，可直接利用标准的https API对ddb内的数据进行读取或者写入操作。\n步骤 1. 创建dynamoDB table 指定表名称，主键即可。\n2. 构建API Get请求 (1) 选择Scan模式：返回DDB中所有结果 新建资源，增加get方法。\n进入Integration Request, 选择DynamoDB服务，action为Scan。\n定义mapping template。\n(2) 选择Query: 查询某项值 新建资源/{year}, 增加get方法。Intergration request的其他选项不变，action改为Query。mapping table更改为如下：\n{ \u0026quot;TableName\u0026quot;: \u0026quot;xxxx\u0026quot;, \u0026quot;KeyConditionExpression\u0026quot;: \u0026quot;account_type = :v1\u0026quot;, \u0026quot;ExpressionAttributeValues\u0026quot;: { \u0026quot;:v1\u0026quot;: { \u0026quot;S\u0026quot;: \u0026quot;$input.params('account_type')\u0026quot; } } }  (3) 测试 选择test测试API。对于query选项，path {year}输入需要查询的value；对于scan无需带参。测试完成后无问题部署即可。\n3. 构建API Post请求 配置如下 mapping table配置如下：\n{ \u0026quot;TableName\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;Item\u0026quot;: { \u0026quot;account_type\u0026quot;: { \u0026quot;S\u0026quot;: \u0026quot;$input.path('$.account_type')\u0026quot; }, \u0026quot;balance\u0026quot;: { \u0026quot;S\u0026quot;: \u0026quot;$input.path('$.balance')\u0026quot; } } }  test时，request body输入数据即可。如\n{ \u0026quot;account_type\u0026quot; : \u0026quot;savings\u0026quot;, \u0026quot;balance\u0026quot; : 1950.21 }  4. 完成部署 选择deploy method完成API部署\n参考连接 https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/api-gateway-create-api-step-by-step.html\nhttps://aws.amazon.com/cn/blogs/compute/using-amazon-api-gateway-as-a-proxy-for-dynamodb/\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/database/mongodb/",
	"title": "将MongoDB部署到现有VPC",
	"tags": [],
	"description": "",
	"content": " 您可以启动Quick Start，将 MongoDB 部署到 AWS 账户中现有的 Virtual Private Cloud (VPC) 中。完成部署需要约 15 分钟。请查看下述实施详细信息，按照此指南后面部分提供的分步说明进行操作。\n \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; \n步骤一：加载Quick Start  在您的 AWS 控制台中选择 AWS CloudFormation ，开始部署 MangoDB 集群。   在配置前，请确保您的VPC在不同可用区中有两个公有子网和三个私有子网（可选），以及 DHCP 选项中配置的域名选项，如 Amazon VPC 文档 中所述。 私有子网需配置 NAT 网关或 NAT 实例以用于出站 Internet 连接，并需创建堡垒主机及其关联的安全组以实现入站 SSH 访问。(请参阅 Amazon VPC 快速入门 设置VPC，Linux 堡垒主机快速入门设置堡垒主机。) 检查导航栏右上角显示的所在区域，根据需要进行更改。 在 Select Template 页面上，若使用默认模板则保留模板 URL 的默认设置，或选择上传您的Template文件，然后选择 Next 。   在 Specify Details 页面上，更改堆栈名称（可选）。填写模板的参数，并仔细检查默认设置中的其他参数，根据需要进行更改（见下表）。完成后选择 Next 进入下一步。  选项 1：用于将 MongoDB 部署到现有 VPC 的参数\n网络配置:\n   参数标签 参数名称 默认值 说明     VPC VPC 需要输入 用于部署MongoDB 群集的 VPC的ID (例如，vpc-0343606e)。   主节点子网 PrimaryNodeSubnet 需要输入 要部署主MongoDB到节点的 VPC 中现有子网的 ID (例如，subnet-a0246dcd)。   Secondary0 节点子网 Secondary0NodeSubnet 需要输入 要部署副本集中第一个辅助 MongoDB 节点的 VPC 中现有子网的 ID。有关预期置放的更多信息，请参阅 架构部分。   Secondary1 节点子网 Secondary1NodeSubnet 需要输入 要部署副本集中第二个辅助 MongoDB 节点的 VPC 中现有子网的 ID。有关预期置放的更多信息，请参阅 架构部分。   堡垒安全组 ID BastionSecurityGroupID 需要输入 现有 VPC 中防御安全组的 ID (例如 sg-7f16e910)。    安全配置：\n   参数标签 参数名称 默认值 说明     密钥名称 KeyPairName 需要输入 公有/私有密钥对，使您能够在实例启动后安全地与它连接。    MongoDB 数据库配置：\n   参数标签 参数名称 默认值 说明     群集副本集计数 ClusterReplicaSetCount 1 副本集成员的数量。选择 1 或 3。   Iops Iops 100 如果选择io1卷类型，需设置为 EBS 卷的 IOPS，否则将忽略此设置。   MongoDB 版本 MongoDBVersion 3.4 将部署的 MongoDB 的版本。   MongoDB 管理员用户名 MongoDBAdminUsername 管理员 MongoDB 管理账户的用户名。   MongoDB 管理员密码 MongoDBAdminPassword 需要输入 您的 MongoDB 数据库密码。您可以输入由以下字符组成的 8-32 个字符的字符串：[A-Za-z0-9_@-]。   节点实例类型 NodeInstanceType m4.large MongoDB 节点的 EC2 实例类型。   副本分区索引 ReplicaShardIndex 0 此副本集的分区索引。有关分区索引的信息，请参阅 MongoDB 文档   卷大小 VolumeSize 400 挂载到 MongoDB 节点的 Amazon EBS (数据) 卷的大小 (以 GiB 为单位)。   卷类型 VolumeType gp2 挂载到 MongoDB 节点 (gp2或io1) 的 Amazon EBS (数据) 卷的卷类型。    AWS 快速入门配置：\n   参数标签 参数名称 默认值 说明     快速入门 S3 存储桶名称 QSS3BucketName quickstart-reference 安装快速入门模板和脚本的 S3 存储桶。如果您希望自定义或扩展快速入门，请使用该参数来指定为该副本创建的 S3 存储桶名称。存储桶名称可包含数字、小写字母、大写字母和连字符，但不得包括连字符开头或结尾。   快速入门 S3 键前缀 QSS3KeyPrefix mongodb/latest/ S3 键名称前缀，用于模拟快速入门资产的副本的文件夹 (如果您决定自定义或扩展快速入门)。此前缀可以包含数字、小写字母、大写字母、连字符和正斜杠。它不赢以连字符 (-) 开头或结尾。     在 Options 页面上，您可以为堆栈中的资源 指定标签 (键/值对) 并 设置高级选项。在完成此操作后，选择 Next 。 在 Review 页面上，查看并确认模板设置。选择 Capabilities 下的复选框，以确认模板将创建 IAM 资源。   选择 Create 以部署堆栈。 监控堆栈的状态。当状态为 CREATE_COMPLETE 时 (如图4所示)，表示 MongoDB 群集已淮备就绪。  步骤二 连接到 MongoDB 节点 当 AWS CloudFormation 模板成功创建堆栈后，您需要通过AWS账户中已安装的软件运行MongoDB 节点。请使用 SSH 连接到堡垒主机实例，以连接到任一 MongoDB 节点，即在 Amazon EC2 控制台中，选择该堡垒实例，然后选择 Connect 。\n使用 SSH 连接到堡垒主机实例后，您可以通过类似的方式连接到任何 MongoDB 节点 (选择节点，然后选择 Connect 以查找 SSH 命令)。\n重要提示\n您需要私有密钥 (.pem) 文件才能连接到 MongoDB 节点。请将私有密钥 (.pem) 文件复制到堡垒主机实例中，例如：\n scp –i mykey.pem mykey.pem ec2-user@Bastion-public-ip:/home/ec2-user/mykey.pem  请注意，所有 MongoDB 节点均通过 IAM 角色来启动，该角色需要权限包括：创建和删除 Amazon DynamoDB 表、访问 Amazon Simple Storage Service (Amazon S3)、创建和删除 Amazon EC2 实例等。您可以使用 IAM 控制台修改该策略。有关 IAM 角色的详细信息请参阅 AWS 文档中的使用 IAM 角色向 Amazon EC2 上运行的应用程序委托权限。\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/storage/s3fs/",
	"title": "Guide: S3FS快速部署",
	"tags": [],
	"description": "",
	"content": " 您可以启动Quick Start，将 S3fs 部署到 AWS 账户中。完成部署需要约 5 分钟。请查看下述实施详细信息，按照此指南后面部分提供的分步说明进行操作。\n \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n前提条件 需要在目标区域，提前创建好一个可用的S3桶用于挂载。cloudformation不会自动生成此通。 且需注意：最终定义的EBS卷的容量需要大于S3桶的总大小。可通过下列方法调用查看桶的大小. 实现步骤 *步骤一：启动资源*\n 在您的 AWS 账户中启动 AWS CloudFormation 模板。   请确保您的账户有一个VPC和私网，如 Amazon VPC中所述。 检查导航栏右上角显示的所在区域，根据需要进行更改。 在 Select Template 页面上，保留模板 URL 的默认设置，然后选择 Next 。   在 Specify Details 页面上，填写堆栈名称及相关参数，根据需要进行更改（见下表）。完成后选择 Next 进入下一步。\n部署S3FS的配置参数\n     参数标签 参数名称 默认值 说明     VPC VpcId 需要输入 将部署S3FS实例的 VPC的ID (例如，vpc-0343606e)。   子网 SubnetId 需要输入 要部署S3FS实例的 VPC 中现有子网的 ID (例如，subnet-a0246dcd)。   密钥名称 KeyName 需要输入 公有/私有密钥对，使您能够在实例启动后安全地与它连接。   S3 存储桶名称 BucketName 需要输入 S3FS实例希望挂载的S3 存储桶(需提前创建好)   实例类型 InstanceType 可选 选择您S3FS实例的实例类型。   EBS卷容量 VolumeSize 需要输入 选择您实例EBS卷的容量（大于S3 bucket大小）   安全组 S3FSSecurityGroup 需要输入 选择您的安全实例(需要保证在选择的VPC下)   目录 S3FSDirectory 需要输入 输入需要与您S3相连的实例的目录。（例如，/mnt/s3）    截图如下：\n 在 Options 页面上，您可以为堆栈中的资源 指定标签 (键/值对) 并 设置高级选项。在完成此操作后，选择 Next 。 在 Review 页面上，查看并确认模板设置。选择 Capabilities 下的复选框，以确认模板将创建 IAM 资源。   选择 Create 以部署堆栈。 监控堆栈的状态。当状态为 CREATE_COMPLETE 时 (如图4所示)，表示群集已准备就绪。在output当中，可以看到用于ssh连接的EC2地址  *步骤二 连接到实例* - 当 AWS CloudFormation 模板成功创建堆栈后，您需要通过SSH连接AWS账户中已安装的S3fs实例。 - 进入目录(例： /mnt/s3mnt )，可发现实例已经与您的S3桶相连。\n限制 利用S3fs可以方便的把S3存储桶挂载在用户本地操作系统目录中，但是由于S3fs实际上是依托于Amazon S3服务提供的目录访问接口，所以不能简单的把S3fs挂载的目录和本地操作系统目录等同使用。用户使用S3f3挂载S3存储桶和直接访问S3服务有类似的使用场景。适用于对不同大小文件对象的一次保存（上传），多次读取（下载）。不适用于对已保存文件经常做随机修改，因为每次在本地修改并保存文件内容都会导致S3fs上传新的文件到Amazon S3去替换原来的文件。从访问性能上来说，通过操作系统目录方式间接访问Amazon S3存储服务的性能不如直接使用SDK或CLI接口访问效率高。以本地配置文件方式保存访问密钥的安全性也不如使用EC2 IAM角色方式高。 关于S3fs使用时候需要注意的更多细节，请参考下面s3fs官网内容：\n通常S3不能提供与本地文件系统相同的性能或语义。进一步来说： * 随机写入或追加到文件需要重写整个文件 * 元数据操作比如列出目录会因为网络延迟原因导致性能较差 * 最终一致性设计可能临时导致过期数据 * 没有对文件或目录的原子重命名功能 * 挂载相同存储桶的多个客户端之间没有相互协调机制 * 不支持硬链接\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/storage/",
	"title": "Storage",
	"tags": [],
	"description": "",
	"content": " NFS: 利用S3FS实现共享存储 自动构建Kafka集群 "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/ai/tensorflow/",
	"title": "Deep Learning AMI下Tensorflow环境的安装与切换",
	"tags": [],
	"description": "",
	"content": " 在AWS Deep Learning AMI的环境下，如何利用conda管理不同环境，配置所需要的依赖，以及创建新的隔离环境。\n文档来源：尹主任\n教程 0.启动EC2实例，选择Deep Learning AMI 1.切换环境 ML AMI自带多套机器学习的环境，如MXNet(+Keras2) with Python3, TensorFlow(+Keras2) with Python3等等。可以利用source activate的命令方便的做切换。如：\n #切换到MXNet with python3.6 source activate mxnet_p36  2.安装新的conda环境  # 通过conda安装环境，并配置对应python版本 $ conda create -n tf_gpu14_p35 python=3.5.2 # 进入环境 $ source activate tf_gpu14_p35 # 进⼊入环境后，可以查看已经安装的包 $ pip list installed #安装tensorflow-gpu $ pip install tensorflow-gpu==1.4 # optional 安装其他的画图相关⼯工具或任意工具 $ pip install tensorflow==1.12 jupyter matplotlib pandas seaborn numpy  3.安装notebook\u0026amp;把conda环境加⼊入notebook中 # Install jupyter notebook $ conda install jupyter $ conda install ipykernel # Add your conda env to jupyter notebook kernels (此处特别注意，加载的时候要在对应的虚拟环境加载，否则会出现找不不到依赖包的问题) $ python -m ipykernel install --user --name tf_gpu14_p35 --display-name \u0026quot;my kernel (tensorflow_gpu14_p35)” # 在base目录Launch Jupyter Notebook $ jupyter notebook  5.通过conda可以设置出多个隔离的交互和训练环境 在对应的训练环境中可以创建对应的ipynb。如果从第三⽅下载的ipynb，必须notebook instance要有对应的环境才可以;比如如下，引入了了第三⽅方的xxx.ipynb，但是其存在于特定的环境conda_mxnet_p36中，但是本机不存在就会报错;\n6.如何查看已经安装的conda env \u0026amp; 如何从notebook中删除conda env 查看列列表 jupyter kernelspec list # 删除特定环境 jupyter kernelspec uninstall unwanted-kernel  7.指定jupyter加载的ipynb的⽬目录 修改配置⽂文件:\n$vim jupyter /home/ubuntu/.jupyter/jupyter_notebook_config.py  修改加载⽬目录\n$c.NotebookApp.notebook_dir = u'/home/ubuntu/TensorFlow-Examples'  参考链接 ###Tensorflow安装\n基于ubuntu16.04安装: https://medium.com/@dichen_5479/setup-tensorflow-gpu-with-aws-ec2-on-ubuntu-16-04-in-10-minutes- 7ee64e47a66a\n基于ubuntu16.04(DeepLearning AMI) https://medium.com/@dichen_5479/launch-an-aws-ec2-instance-with-gpu-for-deep-learning-in-10minutes- 685e5c025ec6\nJupyter Notebook 如何从外部访问notebook https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#notebook-server-security\nSagemaker for tensorflow https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/",
	"title": "Quick Start",
	"tags": [],
	"description": "",
	"content": " Quick Start 介绍 这个项目目的是为了更快的熟悉aws服务，或者在aws上快速部署服务\nDatabase Storage Network CICD Migration IOT Alexa Mobile AI BI "
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/ai/connect_alex/",
	"title": "利用Amazon Connect + Lex 快速构建自己的呼叫中心 &amp; 智能语音机器人",
	"tags": [],
	"description": "",
	"content": " 实验概览 此实验搭建了一个智能电话订车系统，通过语音交互可以获取用户需要订车的城市，取车以及还车时间，对车型的要求，以及驾驶人的年龄，并且将这些信息通过lambda上传到dynamoDB当中.\n架构图 demo效果 可直接拨打+1 443-692-8678测试，触发词\u0026rdquo;reserve\u0026rdquo; \u0026ldquo;reserver a car\u0026rdquo;,\u0026ldquo;book a car\u0026rdquo;等。\n实现步骤 1. 搭建呼叫中心，实现可以人工call in \u0026amp; call out的基本功能 (1) 创建实例，设置基本选项\n打开Amazon Connect，添加实例，设置访问URL，管理用用户密码, 选择功能(call in/ out/both)，通话存储的位置等。  (2) 构建呼叫中心\n点击进入实例（需要管理员密码）。在dashboard当中开始设置。最基本的选项是第一个Claim a phone number，可以选择你的call center number的国家，connect会自动帮你生成一个号码(暂不支持中国+86)。设置完毕后，这个电话就可以使用了，可以进行正常的拨出、拨入，人工对话。 除此之外，你可以定义你的call center的运营时间（比如周一9:00AM-18:00PM, 周六10:00AM-14:00PM,周末不上班）等。其他信息可以暂时不进行设置。  2. 使用Lex创建智能语音机器人 (1) 创建并定义Bot\n打开Lex，创建bots，Lex提供多个模板可供demo选择。这里我们选择基于模板BookTrip。COPPA设置为no。 此时testbots上有两个intents（意图）。代表着用户可以利用此bots做两种触发，一种是订车，一种是订住宿。两者只是定义时的逻辑和数据字段不同，因此此例当中，我们只用到car reservation。 在Interts的设置上，有以下参数： * Sample utterances：唤醒词，可自行定义或添加。 * SLOTS字段：希望Lex帮你获取的信息。默认情况下Lex会按照顺序询问，也可以自己定义priority。 * Fulfillment：定义拿到这些参数之后，下一步希望做什么。可以选择直接把这些信息返回给客户端，或者是利用lambda做进一步的存储、处理、分析等。 * Response：执行完毕后，可以利用这些response做进一步的唤醒。注意，如果这里的fulfillment是lambda，且lambda有return message，将忽略这里的response的设置。 此lab中，我们将用lambda作为car reservation的实现。  此外左侧tab还包括：\n error handling：当获取语音输入失败时，自定义语音，以及重复最多尝试次数。\n slot types: 可以给用户提示，一些选择的example。\n  （2） 创建lambda函数：存储进dynamoDB\n在与Lex同一个region创建lambda函数connect_using_lex。我们将利用这个函数将car reservation环节所得参数存储到dynamoDB当中。请确保lambda的IAM role具有往ddb写入的权限，且提前在ddb当中创建了表connect_lex_car_rent\n基于python 2.7的实例代码如下。\nimport json import boto3 import uuid #替换成自己区域的endpoint dynamodb = boto3.resource('dynamodb', region_name='us-east-1', endpoint_url=\u0026quot;http://dynamodb.us-east-1.amazonaws.com\u0026quot;) def lambda_handler(event, context): print(event['currentIntent']['name']) PickUpCity = event['currentIntent']['slots']['PickUpCity'] PickUpDate = event['currentIntent']['slots']['PickUpDate'] ReturnDate = event['currentIntent']['slots']['ReturnDate'] DriverAge = event['currentIntent']['slots']['DriverAge'] CarType = event['currentIntent']['slots']['CarType'] #dynamoDB table setting table = dynamodb.Table('connect_lex_car_rent') item={ 'id':str(uuid.uuid4()), 'PickUpCity':PickUpCity, 'PickUpDate':PickUpDate, 'ReturnDate':ReturnDate, 'DriverAge':DriverAge, 'CarType':CarType } resp= table.put_item(Item=item) #定义自己的response msg = \u0026quot;Your reservation has been completed, the pickup city is \u0026quot; + PickUpCity return { \u0026quot;sessionAttributes\u0026quot;: {}, \u0026quot;dialogAction\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;Close\u0026quot;, \u0026quot;fulfillmentState\u0026quot;: \u0026quot;Fulfilled\u0026quot;, \u0026quot;message\u0026quot;: { \u0026quot;contentType\u0026quot;: \u0026quot;PlainText\u0026quot;, \u0026quot;content\u0026quot;: msg } } }  （3） 在lex当中指定lambda函数，完成构建\nBookCar Intent的fufillment为此lambda函数，BookHotel不变。保存此intent的编写并build。在build成功后，即可在右侧界面进行文字或者语音的交互测试。且可以看到下方的return当中，lex可以实时的获取这些参数。当测试没有问题后，Publish the bots。\n3. 将Connect与Lex进行集成 回到Amazon Connect，创建自己的contact flow （create contact flow）。实际上是一个逻辑图，所有的逻辑构建都可以拖拽连线完成。左侧的tab提供了丰富的模块选择，他们分别可以提供不同的功能，比如播放，获取输入，存储电话录音等等。 （注：与lex的交互暂不支持语音存储）\n示例如图。 在该示例当中，核心元素块包括：play prompt播放语音或者背景音乐，get customer input获取用户语音或者按键输入，disconnect挂断。\n （1）： 电话接通后，会自动播放欢迎语音（play prompt），询问客户需要什么帮助，等待客户回答（get customer input设置为lex）。\n （2）： 如果客户的描述符合Sample utterances（如reserve，reserve a car等），则成功触发Lex的smart robot。\n （3）： 如无问题(default分支)，则播放感谢语音（play prompt），挂断（disconnect）。\n （4）： 如lex识别语音失败或者客户迟迟没有响应（可设置timeout），则触发另外一个分支error。重新获取用户输入。\n （5）： 等待用户按键响应。按1位重新预定，按0直接退出。 按键是通过DTMF设置的\n  完成自己的逻辑设计后，save \u0026amp; publish.\n4. 绑定电话号码 自定义完contact flow之后，需要将此flow与你的电话号码进行绑定。在dashboard- view phone number当中可以完成此操作。\n监控 \u0026amp; 获取指标 Amazon connect还提供了完善的指标记录。比如可以查询来电数量，来电录音等。在dashboard当中均可以找到。如图，可以查询某一天的来电状况。\n参考链接 https://aws.amazon.com/cn/blogs/contact-center/amazon-connect-with-amazon-lex-press-or-say-input/\nhttps://aws.amazon.com/cn/blogs/aws/new-amazon-connect-and-amazon-lex-integration/\n"
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://d1mo3mx8wgjhk2.cloudfront.net/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]